# 2026-02-20 日志

## 心跳任务（07:02 手动触发）
- 异常检查：全绿（CRIT:0 WARN:0 INFO:5）
- AIOS 基线快照：evolution_score=0.3396 grade=healthy
  - TSR: 96.02%, CR: 11.11%, 502: 0%
  - exec p95 偏高 (6640ms)，其余正常
- 记忆整理：已执行

## 模型切换约定（08:24）
- 日常模式：claude-sonnet-4-5（快速响应）
- 工作模式：claude-opus-4-6（复杂任务）
- 口令："切工作模式" / "切日常模式"（手动覆盖仍有效）
- 自动切换规则（09:47 升级）：
  - 开始干活（改代码/跑测试/多文件操作）→ 自动切 opus，提示"🔧 切工作模式"
  - 干完活 / 进入闲聊 → 自动切 sonnet，提示"💬 切日常模式"
  - 判断依据：我自己的工作量，不是用户消息内容
  - 切换时机：任务开始前 / 任务结束后

## WSL + wacli 安装（07:42-08:22）
- WSL Ubuntu 安装成功
- Go 1.26.0 + wacli 编译成功
- WhatsApp 扫码绑定成功（AUTHENTICATED = true）
- wacli send 命令在 WSL 里一直卡住，网络连接问题未解决
- 结论：wacli 在 WSL 环境下不稳定，暂时搁置

## AIOS insight.py 修复（08:35-08:43）
**问题定位**：
- alerts.py CRIT:0 vs insight.py "致命事件:1" 口径冲突
- 2 条疑似死循环实为部署窗口批量事件误报
- baseline 缺 evolution_score/grade 字段（实为设计如此，不是 bug）

**修复内容**：
- `insight.py`: 致命事件统计拆分为"真实致命事件/测试事件"，输出示例：`致命事件(含测试): 1 (测试1)`
- `insight.py`: 死循环检测排除 `deploy/restart/rollout` 批量事件窗口
- `insight.py`: 新增可追溯字段 `excluded_deploy_restart`，并在报告展示"已排除部署窗口"
- `alerts.py`: 保持 `CRIT:0` 现有规则口径不变（规则检查，不直接读取事件日志）
- `baseline.py`: 不变；`evolution_score`/`grade` 继续由 `evolution_score()` 基于历史快照实时计算

**Commit**: `fix(insight): separate test critical events and exclude deploy/restart windows from loop detection`

## Whisper GPU 升级（07:02-07:14）
- PyTorch 从 CPU 版 2.10.0 升级到 CUDA 12.8 版 (2.87GB 下载，~12.7 MB/s)
- torchvision 0.25.0+cu128, torchaudio 2.10.0+cu128 一并安装
- RTX 5070 Ti 识别成功，torch.cuda.is_available() = True
- Whisper 模型从 small 升级到 medium，GPU 加载 6 秒，占用 ~2.9GB 显存
- whisper_transcribe.py 已更新为 device='cuda'

## 三项提升（09:27-09:38）

### 任务3: Autolearn 模糊匹配可解释性 (v1.1.0)
- `lessons.py` find() 升级为三层匹配：strict → loose → fuzzy (Jaccard)
- 每条结果带 `_match_type`、`_similarity_score`、`_matched_keywords`
- 多候选时返回 `_alternatives`（最多5条）
- `errors.py` 公开 `extract_keywords` 供模糊匹配使用
- `executor.py` 传递 keywords 给 find
- 测试 8/8 全绿

### 任务5: exec p95 偏高排查与修复
- 根因：195 条旧格式模拟数据（全在同一时间戳 2026-02-19T10:38:55）污染了 baseline
- 清理：删除 195 条 v0.1 合成事件，保留 48 条真实 v0.2 事件
- `baseline.py` 升级：新增 `_classify()` 和 `_tool_name_ms()` 兼容 v0.1/v0.2 双格式
- 结果：exec p95 从 6640ms → 300ms，evolution_score 从 0.3396 → 0.4（满分）

### 任务6: 并发与感知带宽
- 新增 `aios/core/event_bus.py`：进程内 pub/sub + 通配符订阅 + 文件队列跨会话通信
- 新增 `aios/core/sensors.py`：三个探针（FileWatcher/ProcessMonitor/SystemHealth）
- 新增 `aios/core/dispatcher.py`：事件调度协调器，感知→分发→行动建议
- 集成到 `alerts.py`：每次异常检查自动跑一轮感知扫描
- 测试 5/5 全绿
- 系统状态：磁盘 50.9%（147.2GB 剩余），内存 44.6%

### 珊瑚海反馈后的两个小改动（09:41-09:43）
- Sensors cooldown：同类事件冷却期内不重复发布（文件10min/进程5min/系统30min）
- Dispatcher trace_id：每轮 dispatch 生成 12 位 hex trace_id，串联感知→决策→动作
- 测试 7/7 + 8/8 全绿
- 版本里程碑：AIOS v0.3 + Autolearn v1.1.0

### 自动模型切换策略（09:46-09:51）
- 新增 `scripts/auto_model.py` v2：基于关键词+长度的消息复杂度分类
- 简单任务（闲聊/查询/确认）→ sonnet，复杂任务（编码/分析/架构）→ opus
- 三个护栏（珊瑚海建议）：
  1. min_dwell_turns=3：至少驻留 3 轮才允许切换，防止频繁抖动
  2. hysteresis：up_threshold=0.72 / down_threshold=0.38，形成滞回避免边界抖动
  3. switch_reason 日志：trace_id + from/to + reason + score + signals，可追溯可迭代
- 测试验证：防抖生效（前 3 轮拦截，第 4 轮放行），日志完整
- 限制：模型在消息到达前已选定，切换在回复后生效（下一条消息用新模型）
- 实际执行：小九在对话中根据自己的工作量判断，调用 should_switch() 决策，然后用 session_status 切换

## 14天运营期数据收集（09:58-10:02）
- 新增 `scripts/ops_metrics.py`：每日收集四个验收指标
  - MTTR: 故障平均恢复时长（从 alerts_history.jsonl）
  - Noise Rate: 告警噪音率（从 alerts_log.jsonl）
  - Retry Yield: 重试挽回率（从 job_queue）
  - Rollback Safety: 回滚成功率（从 changes_log.jsonl）
- 新增 `scripts/ops_weekly.py`：周报生成器（Markdown + Telegram 双格式）
- 每日 9:10 cron 自动收集指标
- 当前状态（Day 2）：Noise Rate 100%，其他指标无数据（系统稳定）

## AIOS 感知层扩展（10:01-10:02）
- 新增 NetworkProbe：网络连通性检测（ping 8.8.8.8 / 1.1.1.1 / api.anthropic.com）
- 状态变化检测：可达→不可达 发 HIGH 告警，恢复时发 NORMAL 通知
- Cooldown 10分钟，避免网络抖动重复告警
- 已集成到 dispatcher，测试 7/7 全绿
- 当前网络状态：3个目标全部可达

## 自动模型切换实战测试（10:04-10:18）
- v3 尝试（灰区+dwell累积+时间冷却）：4/10 准确率，太保守
- 回退 v2，微调后 9/10 准确率
- v3 教训：多重护栏叠加会导致切换过于保守，简单的 min_dwell + hysteresis 反而更实用
- 最终版本：v2（min_dwell=3, up=0.72, down=0.45）
- 珊瑚海提供的 v3 伪代码留作参考，等 v2 在实际使用中暴露问题再升级
