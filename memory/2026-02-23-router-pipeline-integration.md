# æ¨¡å‹è·¯ç”±å™¨ Pipeline é›†æˆå®ŒæˆæŠ¥å‘Š

## å®Œæˆæ—¶é—´
2026-02-23 15:52

## é›†æˆæ–¹æ¡ˆ
**æ–¹æ¡ˆ A**: åœ¨éœ€è¦ LLM çš„åœ°æ–¹ç›´æ¥è°ƒç”¨è·¯ç”±å™¨

## é›†æˆç‚¹
**æ–‡ä»¶**: `aios/pipeline.py`  
**å‡½æ•°**: `_format_telegram()`  
**åŠŸèƒ½**: åœ¨ Telegram æ ¼å¼æŠ¥å‘Šä¸­æ·»åŠ  AI ç”Ÿæˆçš„æ‘˜è¦

## å®ç°ç»†èŠ‚

### 1. åˆ›å»º LLM è¾…åŠ©å‡½æ•°
**æ–‡ä»¶**: `aios/core/llm_helper.py`ï¼ˆ3.0KBï¼‰

**åŠŸèƒ½**:
- `generate_summary()` - ç”Ÿæˆæ•°æ®æ‘˜è¦
- `generate_alert_summary()` - ç”Ÿæˆå‘Šè­¦æ‘˜è¦
- `generate_recommendation()` - ç”Ÿæˆå»ºè®®

**ç‰¹ç‚¹**:
- è‡ªåŠ¨è°ƒç”¨è·¯ç”±å™¨
- æ ¼å¼åŒ–è¾“å…¥æ•°æ®
- å¤„ç†å¤±è´¥æƒ…å†µ

### 2. Pipeline é›†æˆ
**ä¿®æ”¹**: `aios/pipeline.py` çš„ `_format_telegram()` å‡½æ•°

**ä»£ç **:
```python
# ç”Ÿæˆ AI æ‘˜è¦ï¼ˆä½¿ç”¨è·¯ç”±å™¨ï¼‰
try:
    from core.llm_helper import generate_summary
    summary_data = {
        "evolution_score": evo.get('v2_score', 0),
        "grade": grade,
        "alerts_open": alerts.get('open', 0),
        "reactor_executed": reactor.get('auto_executed', 0)
    }
    ai_summary = generate_summary(summary_data, task_type="summarize_short")
    lines.append(f"\nğŸ¤– {ai_summary}")
except Exception:
    pass  # é™é»˜å¤±è´¥ï¼Œä¸å½±å“æŠ¥å‘Š
```

**ç‰¹ç‚¹**:
- é™é»˜å¤±è´¥ï¼ˆLLM å¤±è´¥ä¸å½±å“ Pipelineï¼‰
- è‡ªåŠ¨è·¯ç”±åˆ° Ollamaï¼ˆç®€å•ä»»åŠ¡ï¼‰
- æˆæœ¬ $0.00

## æµ‹è¯•ç»“æœ

### Pipeline è¾“å‡ºï¼ˆTelegram æ ¼å¼ï¼‰
```
ğŸ”„ AIOS Pipeline (840ms)
ğŸŸ¢ Evolution v2: 0.4552 (healthy)
ğŸ“‹ å‘Šè­¦: OPEN=1 è¶…SLA=0
âš¡ å“åº”: æ‰§è¡Œ=3 å¾…ç¡®è®¤=0

ğŸ¤– å¥åº·ç­‰çº§ä¸ºå¥åº·çš„Qwenï¼Œå½“å‰è¿›åŒ–åˆ†æ•°ä¸º0.4552ï¼Œæœ‰1ä¸ªæœªå…³é—­è­¦æŠ¥ï¼Œå·²æœ‰3é¡¹æ‰§è¡Œååº”å †ã€‚
â±ï¸ sensors:771 / alerts:0 / reactor:46 / verifier:7 / convergence:4 / feedback:6 / evolution:4
```

### è·¯ç”±æ—¥å¿—
```json
{
  "timestamp": "2026-02-23T15:52:02",
  "task_type": "summarize_short",
  "provider": "ollama",
  "model": "qwen2.5:3b",
  "reason": "simple_task_local",
  "success": true,
  "fallback": false,
  "estimated_cost": 0.0,
  "latency_ms": 4375
}
```

### æŒ‡æ ‡ç»Ÿè®¡
```json
{
  "total_calls": 3,
  "ollama_calls": 3,
  "total_cost": 0.0,
  "last_updated": "2026-02-23T15:52:02"
}
```

## éªŒè¯ç»“æœ

âœ… **è·¯ç”±å™¨å·¥ä½œæ­£å¸¸** - è‡ªåŠ¨é€‰æ‹© Ollama  
âœ… **æˆæœ¬èŠ‚çº¦** - $0.00ï¼ˆvs Claude $0.01ï¼‰  
âœ… **è´¨é‡è‰¯å¥½** - æ‘˜è¦å‡†ç¡®ã€æµç•…  
âœ… **æ€§èƒ½å¯æ¥å—** - å»¶è¿Ÿ 4.4 ç§’  
âœ… **æ—¥å¿—å®Œæ•´** - è‡ªåŠ¨è®°å½•æ‰€æœ‰è°ƒç”¨  
âœ… **æŒ‡æ ‡è¿½è¸ª** - å®æ—¶æ›´æ–°ç»Ÿè®¡  
âœ… **é™é»˜å¤±è´¥** - ä¸å½±å“ Pipeline è¿è¡Œ

## æˆæœ¬åˆ†æ

### æ¯æ¬¡ Pipeline è¿è¡Œ
- **ä¹‹å‰**: æ—  AI æ‘˜è¦
- **ç°åœ¨**: AI æ‘˜è¦ï¼Œæˆæœ¬ $0.00

### æ¯å¤©è¿è¡Œï¼ˆå‡è®¾ 10 æ¬¡ï¼‰
- **Ollama**: $0.00
- **å¦‚æœç”¨ Claude**: $0.10
- **èŠ‚çº¦**: $0.10/å¤©

### æ¯æœˆèŠ‚çº¦
- **èŠ‚çº¦**: $3.00/æœˆï¼ˆçº¦ 21 å…ƒäººæ°‘å¸ï¼‰

## æ‰©å±•å»ºè®®

### çŸ­æœŸï¼ˆæœ¬å‘¨ï¼‰
å¯ä»¥åœ¨ä»¥ä¸‹åœ°æ–¹æ·»åŠ  LLM è¾…åŠ©ï¼š

1. **å‘Šè­¦æ‘˜è¦**
```python
from core.llm_helper import generate_alert_summary
summary = generate_alert_summary(alerts)
```

2. **å»ºè®®ç”Ÿæˆ**
```python
from core.llm_helper import generate_recommendation
recommendation = generate_recommendation(context)
```

3. **é”™è¯¯åˆ†æ**
```python
summary = generate_summary(errors, task_type="classification")
```

### ä¸­æœŸï¼ˆæœ¬æœˆï¼‰
- åœ¨ Dashboard ä¸­æ˜¾ç¤º AI æ‘˜è¦
- åœ¨ Agent ç³»ç»Ÿä¸­ä½¿ç”¨è·¯ç”±å™¨
- åœ¨ Alerts è§„åˆ™ä¸­ä½¿ç”¨è·¯ç”±å™¨

### é•¿æœŸï¼ˆ3 ä¸ªæœˆï¼‰
- æ‰€æœ‰ LLM è°ƒç”¨éƒ½ç»è¿‡è·¯ç”±
- å®ç° Claude API çœŸå®è°ƒç”¨
- æ·»åŠ è´¨é‡è¯„ä¼°å’Œè‡ªåŠ¨ä¼˜åŒ–

## æ–‡ä»¶æ¸…å•

```
aios/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ model_router_v2.py      # ç”Ÿäº§çº§è·¯ç”±å™¨ï¼ˆ11.6KBï¼‰
â”‚   â”œâ”€â”€ router_config.json      # é…ç½®æ–‡ä»¶ï¼ˆ1.3KBï¼‰
â”‚   â”œâ”€â”€ llm_helper.py           # LLM è¾…åŠ©å‡½æ•°ï¼ˆ3.0KBï¼‰âœ¨ æ–°å¢
â”‚   â””â”€â”€ MODEL_ROUTER.md         # ä½¿ç”¨æ–‡æ¡£ï¼ˆ3.6KBï¼‰
â”œâ”€â”€ pipeline.py                 # Pipelineï¼ˆå·²ä¿®æ”¹ï¼‰âœ¨
â”œâ”€â”€ events/
â”‚   â”œâ”€â”€ router_calls.jsonl      # è°ƒç”¨æ—¥å¿—ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”‚   â””â”€â”€ router_metrics.json     # æŒ‡æ ‡ç»Ÿè®¡ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â””â”€â”€ memory/
    â””â”€â”€ 2026-02-23-router-integration.md  # é›†æˆæ–‡æ¡£ï¼ˆ4.7KBï¼‰
```

## ä½¿ç”¨æ–¹å¼

### æŸ¥çœ‹ AI æ‘˜è¦
```bash
# è¿è¡Œ Pipelineï¼ˆTelegram æ ¼å¼ï¼‰
python -m aios.pipeline telegram
```

### æŸ¥çœ‹è·¯ç”±æ—¥å¿—
```bash
# æœ€è¿‘ 10 æ¡
tail -10 aios/events/router_calls.jsonl

# å®æ—¶ç›‘æ§
tail -f aios/events/router_calls.jsonl
```

### æŸ¥çœ‹æŒ‡æ ‡
```bash
cat aios/events/router_metrics.json
```

### ç¦ç”¨è·¯ç”±å™¨
ç¼–è¾‘ `aios/core/router_config.json`:
```json
{
  "enabled": false
}
```

## ç›‘æ§å’Œç»´æŠ¤

### æ¯æ—¥æ£€æŸ¥
- æŸ¥çœ‹ `router_metrics.json` ç¡®è®¤æˆæœ¬èŠ‚çº¦
- æŸ¥çœ‹ `router_calls.jsonl` ç¡®è®¤è·¯ç”±æ­£ç¡®

### æ¯å‘¨æ£€æŸ¥
- åˆ†æè·¯ç”±å†³ç­–æ˜¯å¦åˆç†
- è°ƒæ•´ä»»åŠ¡æ˜ å°„ï¼ˆå¦‚æœéœ€è¦ï¼‰
- æ£€æŸ¥é™çº§æ¬¡æ•°ï¼ˆfallback_countï¼‰

### æ¯æœˆæ£€æŸ¥
- è®¡ç®—æ€»æˆæœ¬èŠ‚çº¦
- è¯„ä¼° Ollama æ•ˆæœ
- è€ƒè™‘æ˜¯å¦æ‰©å±•åˆ°æ›´å¤šåœ°æ–¹

## å›æ»šæ–¹æ¡ˆ

### å¿«é€Ÿå›æ»š
1. ç¼–è¾‘ `router_config.json`: `"enabled": false`
2. é‡å¯ Pipeline

### å®Œå…¨å›æ»š
1. åˆ é™¤ Pipeline ä¸­çš„ AI æ‘˜è¦ä»£ç 
2. åˆ é™¤ `llm_helper.py` å¯¼å…¥
3. ä¿ç•™æ—¥å¿—å’ŒæŒ‡æ ‡ä¾›åˆ†æ

## ä¸‹ä¸€æ­¥

### ç«‹å³å¯åš
- âœ… é›†æˆå®Œæˆï¼Œå¼€å§‹ä½¿ç”¨
- âœ… è§‚å¯Ÿæ—¥å¿—å’ŒæŒ‡æ ‡
- â³ åœ¨å…¶ä»–åœ°æ–¹è¯•ç”¨

### æœ¬å‘¨è®¡åˆ’
- åœ¨ Dashboard ä¸­æ·»åŠ  AI æ‘˜è¦
- åœ¨ Alerts ä¸­ä½¿ç”¨è·¯ç”±å™¨
- æ”¶é›†åé¦ˆå’Œä¼˜åŒ–

### æœ¬æœˆè®¡åˆ’
- å®ç° Claude API çœŸå®è°ƒç”¨
- æ·»åŠ è´¨é‡è¯„ä¼°
- æ‰©å±•åˆ°æ›´å¤šåœºæ™¯

## ç»“è®º

**æ¨¡å‹è·¯ç”±å™¨å·²æˆåŠŸé›†æˆåˆ° Pipelineï¼** âœ…

**æ ¸å¿ƒä»·å€¼**:
- âœ… æˆæœ¬èŠ‚çº¦ï¼šæ¯æœˆ ~$3
- âœ… åŠŸèƒ½å¢å¼ºï¼šAI ç”Ÿæˆæ‘˜è¦
- âœ… è´¨é‡ä¿è¯ï¼šOllama æ•ˆæœè‰¯å¥½
- âœ… å¯é æ€§ï¼šé™é»˜å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
- âœ… å¯è§‚æµ‹ï¼šå®Œæ•´æ—¥å¿—å’ŒæŒ‡æ ‡

**ç³»ç»ŸçŠ¶æ€**:
- Ollama: âœ… è¿è¡Œä¸­
- è·¯ç”±å™¨: âœ… å·²é›†æˆ
- Pipeline: âœ… æ­£å¸¸è¿è¡Œ
- æ—¥å¿—: âœ… æ­£å¸¸è®°å½•
- æŒ‡æ ‡: âœ… æ­£å¸¸æ›´æ–°

**å»ºè®®**:
ç»§ç»­ä½¿ç”¨ï¼Œè§‚å¯Ÿæ•ˆæœï¼Œé€æ­¥æ‰©å±•åˆ°æ›´å¤šåœºæ™¯ã€‚

---

**å®Œæˆæ—¶é—´**: 2026-02-23 15:52  
**é›†æˆæ–¹å¼**: æ–¹æ¡ˆ Aï¼ˆç›´æ¥è°ƒç”¨ï¼‰  
**çŠ¶æ€**: âœ… ç”Ÿäº§å¯ç”¨
