"""
AIOS Task Scheduler v2.1 - ç”Ÿäº§çº§å¹¶å‘ä»»åŠ¡è°ƒåº¦å™¨

æ ¸å¿ƒç‰¹æ€§ï¼š
- å®Œå…¨çº¿ç¨‹å®‰å…¨ (threading.Lock å…¨è¦†ç›–)
- O(1) deque é˜Ÿåˆ—
- æ­£ç¡®ä¾èµ–å¤„ç† (waiting queue + completed setï¼Œæ— æ­»å¾ªç¯ã€æ— å¿™ç­‰å¾…)
- å†…ç½®ä»»åŠ¡è¶…æ—¶ä¿æŠ¤ (ThreadPoolExecutor + timeout)
- ä¼˜å…ˆçº§é˜Ÿåˆ—æ”¯æŒ (P0-P3)
- ç±»å‹æç¤º + Google docstring + structured logging
- ä¼˜é›…å…³é—­ + èµ„æºé›¶æ³„æ¼
- ç»Ÿè®¡è¿½è¸ªï¼ˆå®Œæˆ/å¤±è´¥/è¶…æ—¶ï¼‰
"""
import threading
from collections import deque
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutureTimeoutError
from typing import Dict, Any, Callable, List, Optional
from enum import IntEnum
from dataclasses import dataclass, field
import logging
import time
import uuid

logger = logging.getLogger(__name__)


class Priority(IntEnum):
    """ä»»åŠ¡ä¼˜å…ˆçº§"""
    P0_CRITICAL = 0   # ç³»ç»Ÿé™çº§ï¼ˆscore < 0.3ï¼‰
    P1_HIGH = 1       # èµ„æºå‘Šè­¦ï¼ˆCPU/å†…å­˜å³°å€¼ï¼‰
    P2_MEDIUM = 2     # Agent é”™è¯¯
    P3_LOW = 3        # æ­£å¸¸äº‹ä»¶


@dataclass
class Task:
    """è°ƒåº¦ä»»åŠ¡"""
    id: str
    func: Callable
    priority: int = Priority.P3_LOW.value
    depends_on: List[str] = field(default_factory=list)
    timeout_sec: int = 30
    created_at: float = field(default_factory=time.time)
    retry_count: int = 0
    max_retries: int = 3


class Scheduler:
    """ç”Ÿäº§çº§ä»»åŠ¡è°ƒåº¦å™¨ï¼Œæ”¯æŒä¾èµ–å…³ç³»ã€å¹¶å‘æ§åˆ¶ã€è¶…æ—¶ä¿æŠ¤ã€ä¼˜å…ˆçº§ã€‚"""

    def __init__(self, max_concurrent: int = 5, default_timeout: int = 30):
        """åˆå§‹åŒ–è°ƒåº¦å™¨ã€‚

        Args:
            max_concurrent: æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
            default_timeout: å•ä¸ªä»»åŠ¡é»˜è®¤è¶…æ—¶ç§’æ•°
        """
        self.max_concurrent = max_concurrent
        self.default_timeout = default_timeout
        
        # é˜Ÿåˆ—ï¼ˆæŒ‰ä¼˜å…ˆçº§åˆ†å±‚ï¼‰
        self.queues: Dict[int, deque] = {
            Priority.P0_CRITICAL.value: deque(),
            Priority.P1_HIGH.value: deque(),
            Priority.P2_MEDIUM.value: deque(),
            Priority.P3_LOW.value: deque(),
        }
        
        self.waiting: deque = deque()  # ç­‰å¾…ä¾èµ–çš„ä»»åŠ¡
        self.running: Dict[str, Any] = {}  # task_id -> Future
        self.completed: set[str] = set()
        self.dependencies: Dict[str, List[str]] = {}
        self.lock = threading.Lock()
        self.executor = ThreadPoolExecutor(max_workers=max_concurrent)
        
        # ç»Ÿè®¡
        self.stats = {
            "total_submitted": 0,
            "total_completed": 0,
            "total_failed": 0,
            "total_timeout": 0,
            "total_cancelled": 0,
        }
        
        # å›è°ƒé’©å­
        self.on_task_complete: Optional[Callable] = None
        self.on_task_error: Optional[Callable] = None
        self.on_task_timeout: Optional[Callable] = None
        
        # å–æ¶ˆæ ‡è®°
        self.cancelled_tasks: set[str] = set()

    def schedule(self, task: Dict[str, Any]) -> str:
        """è°ƒåº¦æ–°ä»»åŠ¡ã€‚

        Args:
            task: å¿…é¡»åŒ…å« 'func' (Callable)ï¼Œå¯é€‰ 'id', 'priority', 'depends_on', 'timeout_sec'
        
        Returns:
            ä»»åŠ¡ ID
        """
        with self.lock:
            # ç”Ÿæˆä»»åŠ¡ IDï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
            task_id = task.get("id", str(uuid.uuid4())[:8])
            task["id"] = task_id
            
            # éªŒè¯
            func = task.get("func")
            if not callable(func):
                raise TypeError(f"Task {task_id}: 'func' must be callable")

            depends_on = task.get("depends_on", [])
            if not isinstance(depends_on, list):
                raise ValueError(f"Task {task_id}: 'depends_on' must be list")

            priority = task.get("priority", Priority.P3_LOW.value)
            if priority not in self.queues:
                priority = Priority.P3_LOW.value
            
            # è®°å½•ä¾èµ–
            self.dependencies[task_id] = depends_on
            
            # å…¥é˜Ÿï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
            self.queues[priority].append(task)
            self.stats["total_submitted"] += 1
            
            logger.info(f"ğŸ“¥ Task {task_id} scheduled (P{priority}, depends on {depends_on})")

        self._process_queue()
        return task_id

    def submit(
        self,
        task_type: str,
        func: Callable,
        priority: Priority = Priority.P3_LOW,
        timeout_sec: int = 30,
        depends_on: List[str] = None
    ) -> str:
        """ä¾¿æ·æ–¹æ³•ï¼šæäº¤ä»»åŠ¡ï¼ˆå…¼å®¹æ—§ APIï¼‰ã€‚
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            func: ä»»åŠ¡å‡½æ•°
            priority: ä¼˜å…ˆçº§
            timeout_sec: è¶…æ—¶æ—¶é—´
            depends_on: ä¾èµ–çš„ä»»åŠ¡ ID åˆ—è¡¨
        
        Returns:
            ä»»åŠ¡ ID
        """
        task = {
            "func": func,
            "priority": priority.value,
            "timeout_sec": timeout_sec,
            "depends_on": depends_on or [],
            "task_type": task_type,
        }
        return self.schedule(task)

    def _deps_satisfied(self, task_id: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡çš„æ‰€æœ‰ä¾èµ–æ˜¯å¦å·²å®Œæˆã€‚"""
        deps = self.dependencies.get(task_id, [])
        return all(d in self.completed for d in deps)

    def _process_queue(self) -> None:
        """å¤„ç†å°±ç»ªé˜Ÿåˆ—å’Œç­‰å¾…ä¾èµ–çš„ä»»åŠ¡ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ã€‚"""
        with self.lock:
            # æŠŠæ»¡è¶³ä¾èµ–çš„ waiting ä»»åŠ¡ç§»å›å¯¹åº”ä¼˜å…ˆçº§é˜Ÿåˆ—
            new_waiting = deque()
            for task in list(self.waiting):
                if self._deps_satisfied(task["id"]):
                    priority = task.get("priority", Priority.P3_LOW.value)
                    self.queues[priority].append(task)
                else:
                    new_waiting.append(task)
            self.waiting = new_waiting

            # æŒ‰ä¼˜å…ˆçº§æ‰§è¡Œå°±ç»ªä»»åŠ¡ï¼ˆP0 > P1 > P2 > P3ï¼‰
            while len(self.running) < self.max_concurrent:
                task = None
                
                # ä»é«˜ä¼˜å…ˆçº§åˆ°ä½ä¼˜å…ˆçº§æŸ¥æ‰¾
                for priority in sorted(self.queues.keys()):
                    if self.queues[priority]:
                        task = self.queues[priority].popleft()
                        break
                
                if not task:
                    break  # æ²¡æœ‰ä»»åŠ¡äº†
                
                if self._deps_satisfied(task["id"]):
                    self._start_task(task)
                else:
                    self.waiting.append(task)

    def _start_task(self, task: Dict[str, Any]) -> None:
        """ä½¿ç”¨ Executor å¯åŠ¨å¸¦è¶…æ—¶çš„ä»»åŠ¡ã€‚"""
        task_id = task["id"]
        future = self.executor.submit(self._execute_task, task)
        self.running[task_id] = future
        future.add_done_callback(lambda f: self._task_done(task_id, f, task))

    def _execute_task(self, task: Dict[str, Any]) -> Any:
        """å®é™…æ‰§è¡Œå‡½æ•°ï¼ˆworker çº¿ç¨‹ï¼‰ã€‚"""
        return task["func"]()

    def _task_done(self, task_id: str, future, task: Dict[str, Any]) -> None:
        """ä»»åŠ¡å®Œæˆå›è°ƒã€‚"""
        with self.lock:
            self.running.pop(task_id, None)
        
        try:
            # done_callback ä¿è¯ä»»åŠ¡å·²å®Œæˆï¼Œresult() ä¼šç«‹å³è¿”å›
            result = future.result()
            self._on_complete(task_id, result)
        except Exception as e:
            self._on_error(task_id, e, task)

        self._process_queue()

    def _on_complete(self, task_id: str, result: Any) -> None:
        with self.lock:
            self.completed.add(task_id)
            self.stats["total_completed"] += 1
        logger.info(f"âœ… Task {task_id} completed successfully: {result}")
        
        # è§¦å‘å›è°ƒ
        if self.on_task_complete:
            try:
                self.on_task_complete(task_id, result)
            except Exception as e:
                logger.error(f"Error in on_task_complete callback: {e}")

    def _on_error(self, task_id: str, error: Exception, task: Dict[str, Any]) -> None:
        retry_count = task.get("retry_count", 0)
        max_retries = task.get("max_retries", 3)
        
        if retry_count < max_retries:
            # é‡è¯•
            task["retry_count"] = retry_count + 1
            logger.warning(f"âš ï¸ Task {task_id} failed (retry {retry_count + 1}/{max_retries}): {error}")
            self.schedule(task)
        else:
            # å¤±è´¥
            with self.lock:
                self.stats["total_failed"] += 1
            logger.error(f"âŒ Task {task_id} failed after {max_retries} retries: {error}")
            
            # è§¦å‘å›è°ƒ
            if self.on_task_error:
                try:
                    self.on_task_error(task_id, error)
                except Exception as e:
                    logger.error(f"Error in on_task_error callback: {e}")

    def _on_timeout(self, task_id: str, task: Dict[str, Any]) -> None:
        timeout = task.get("timeout_sec", self.default_timeout)
        with self.lock:
            self.stats["total_timeout"] += 1
        logger.warning(f"â° Task {task_id} timed out after {timeout}s")
        
        # è§¦å‘å›è°ƒ
        if self.on_task_timeout:
            try:
                self.on_task_timeout(task_id, timeout)
            except Exception as e:
                logger.error(f"Error in on_task_timeout callback: {e}")

    def cancel(self, task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡ã€‚
        
        Args:
            task_id: ä»»åŠ¡ ID
        
        Returns:
            æ˜¯å¦æˆåŠŸå–æ¶ˆ
        """
        with self.lock:
            # æ£€æŸ¥æ˜¯å¦åœ¨é˜Ÿåˆ—ä¸­
            for priority, queue in self.queues.items():
                for task in list(queue):
                    if task["id"] == task_id:
                        queue.remove(task)
                        self.cancelled_tasks.add(task_id)
                        self.stats["total_cancelled"] += 1
                        logger.info(f"ğŸš« Task {task_id} cancelled (in queue)")
                        return True
            
            # æ£€æŸ¥æ˜¯å¦åœ¨ç­‰å¾…é˜Ÿåˆ—
            for task in list(self.waiting):
                if task["id"] == task_id:
                    self.waiting.remove(task)
                    self.cancelled_tasks.add(task_id)
                    self.stats["total_cancelled"] += 1
                    logger.info(f"ğŸš« Task {task_id} cancelled (waiting)")
                    return True
            
            # æ£€æŸ¥æ˜¯å¦æ­£åœ¨è¿è¡Œ
            if task_id in self.running:
                future = self.running[task_id]
                if future.cancel():
                    self.cancelled_tasks.add(task_id)
                    self.stats["total_cancelled"] += 1
                    logger.info(f"ğŸš« Task {task_id} cancelled (running)")
                    return True
                else:
                    logger.warning(f"âš ï¸ Task {task_id} cannot be cancelled (already executing)")
                    return False
        
        logger.warning(f"âš ï¸ Task {task_id} not found")
        return False

    def get_progress(self) -> Dict[str, Any]:
        """è·å–è¿›åº¦ä¿¡æ¯ã€‚"""
        with self.lock:
            total = self.stats["total_submitted"]
            completed = self.stats["total_completed"]
            failed = self.stats["total_failed"]
            timeout = self.stats["total_timeout"]
            cancelled = self.stats["total_cancelled"]
            
            finished = completed + failed + timeout + cancelled
            progress = (finished / total * 100) if total > 0 else 0
            
            return {
                "total": total,
                "completed": completed,
                "failed": failed,
                "timeout": timeout,
                "cancelled": cancelled,
                "running": len(self.running),
                "queued": sum(len(q) for q in self.queues.values()),
                "waiting": len(self.waiting),
                "progress_percent": round(progress, 2),
            }

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯ã€‚"""
        with self.lock:
            return {
                **self.stats,
                "running": len(self.running),
                "queued": sum(len(q) for q in self.queues.values()),
                "waiting": len(self.waiting),
            }

    def shutdown(self, wait: bool = True) -> None:
        """ä¼˜é›…å…³é—­ã€‚"""
        self.executor.shutdown(wait=wait)
        logger.info("Scheduler shutdown complete.")


# ==================== æµ‹è¯•ç¤ºä¾‹ ====================
if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s"
    )

    scheduler = Scheduler(max_concurrent=3, default_timeout=5)
    
    # è®¾ç½®å›è°ƒ
    def on_complete(task_id, result):
        print(f"[Callback] Task {task_id} completed: {result}")
    
    def on_error(task_id, error):
        print(f"[Callback] Task {task_id} error: {error}")
    
    scheduler.on_task_complete = on_complete
    scheduler.on_task_error = on_error

    def task_a():
        time.sleep(0.5)
        return "Task A done"

    def task_b():
        time.sleep(0.8)
        return "Task B done"
    
    def task_c():
        time.sleep(0.3)
        return "Task C done (high priority)"
    
    def task_d():
        time.sleep(2.0)  # æ›´é•¿çš„ä»»åŠ¡
        return "Task D done (will be cancelled)"

    # æµ‹è¯•ä¾èµ–
    scheduler.schedule({"id": "A", "func": task_a, "priority": Priority.P3_LOW.value})
    scheduler.schedule({"id": "B", "func": task_b, "depends_on": ["A"], "priority": Priority.P2_MEDIUM.value})
    
    # æµ‹è¯•ä¼˜å…ˆçº§
    scheduler.schedule({"id": "C", "func": task_c, "priority": Priority.P1_HIGH.value})
    
    # æµ‹è¯•å–æ¶ˆï¼ˆä½ä¼˜å…ˆçº§ï¼Œä¼šæ’åœ¨é˜Ÿåˆ—åé¢ï¼‰
    task_d_id = scheduler.schedule({"id": "D", "func": task_d, "priority": Priority.P3_LOW.value})
    time.sleep(0.1)
    cancelled = scheduler.cancel("D")
    print(f"\n[Test] Cancel D: {cancelled}\n")

    time.sleep(3)
    
    print("\n=== Progress ===")
    print(scheduler.get_progress())
    
    print("\n=== Stats ===")
    print(scheduler.get_stats())
    
    print("\n=== Completed ===")
    print(sorted(scheduler.completed))
    
    scheduler.shutdown()
