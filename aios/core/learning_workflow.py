"""
AIOS è‡ªå­¦ä¹ å·¥ä½œæµ
ä»æ¯æ¬¡æ‰§è¡Œä¸­å­¦ä¹ ï¼ŒæŒç»­æ”¹è¿›ç³»ç»Ÿæ€§èƒ½

å­¦ä¹ å†…å®¹ï¼š
1. Provider æ€§èƒ½ï¼ˆå“ªä¸ªæ¨¡å‹æˆåŠŸç‡é«˜ï¼‰
2. Playbook æ•ˆæœï¼ˆå“ªäº›è§„åˆ™æœ‰æ•ˆï¼‰
3. ä»»åŠ¡è·¯ç”±ï¼ˆå“ªç§ä»»åŠ¡é€‚åˆå“ªä¸ª Agentï¼‰
4. èµ„æºé˜ˆå€¼ï¼ˆä»€ä¹ˆæ—¶å€™è¯¥è§¦å‘å‘Šè­¦ï¼‰
5. ç”¨æˆ·åå¥½ï¼ˆç”¨æˆ·å–œæ¬¢ä»€ä¹ˆæ ·çš„å“åº”ï¼‰
"""
import json
import time
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any
from collections import defaultdict


class LearningWorkflow:
    """è‡ªå­¦ä¹ å·¥ä½œæµ"""
    
    def __init__(self, workspace: Path = None):
        """
        åˆå§‹åŒ–
        
        Args:
            workspace: å·¥ä½œç›®å½•
        """
        if workspace is None:
            workspace = Path(__file__).parent.parent.parent
        
        self.workspace = Path(workspace)
        self.learning_dir = self.workspace / "aios" / "learning"
        self.learning_dir.mkdir(parents=True, exist_ok=True)
        
        # å­¦ä¹ æ•°æ®æ–‡ä»¶
        self.provider_stats_file = self.learning_dir / "provider_stats.json"
        self.playbook_stats_file = self.learning_dir / "playbook_stats.json"
        self.task_routing_file = self.learning_dir / "task_routing.json"
        self.threshold_history_file = self.learning_dir / "threshold_history.jsonl"
        self.user_feedback_file = self.learning_dir / "user_feedback.jsonl"
    
    # ========== 1. Provider æ€§èƒ½å­¦ä¹  ==========
    
    def record_provider_execution(
        self,
        provider: str,
        success: bool,
        duration: float,
        task_type: str,
        error: str = None
    ):
        """
        è®°å½• Provider æ‰§è¡Œç»“æœ
        
        Args:
            provider: Provider åç§°
            success: æ˜¯å¦æˆåŠŸ
            duration: æ‰§è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰
            task_type: ä»»åŠ¡ç±»å‹
            error: é”™è¯¯ä¿¡æ¯
        """
        stats = self._load_provider_stats()
        
        if provider not in stats:
            stats[provider] = {
                "total_executions": 0,
                "success_count": 0,
                "fail_count": 0,
                "total_duration": 0,
                "avg_duration": 0,
                "success_rate": 0,
                "by_task_type": {}
            }
        
        p = stats[provider]
        p["total_executions"] += 1
        
        if success:
            p["success_count"] += 1
        else:
            p["fail_count"] += 1
        
        p["total_duration"] += duration
        p["avg_duration"] = p["total_duration"] / p["total_executions"]
        p["success_rate"] = p["success_count"] / p["total_executions"]
        
        # æŒ‰ä»»åŠ¡ç±»å‹ç»Ÿè®¡
        if task_type not in p["by_task_type"]:
            p["by_task_type"][task_type] = {
                "count": 0,
                "success": 0,
                "fail": 0
            }
        
        p["by_task_type"][task_type]["count"] += 1
        if success:
            p["by_task_type"][task_type]["success"] += 1
        else:
            p["by_task_type"][task_type]["fail"] += 1
        
        self._save_provider_stats(stats)
    
    def get_best_provider(self, task_type: str = None) -> str:
        """
        è·å–æœ€ä½³ Provider
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            æœ€ä½³ Provider åç§°
        """
        stats = self._load_provider_stats()
        
        if not stats:
            return "claude-sonnet-4-6"  # é»˜è®¤
        
        # å¦‚æœæŒ‡å®šäº†ä»»åŠ¡ç±»å‹ï¼ŒæŒ‰ä»»åŠ¡ç±»å‹é€‰æ‹©
        if task_type:
            best_provider = None
            best_score = 0
            
            for provider, p_stats in stats.items():
                if task_type in p_stats["by_task_type"]:
                    task_stats = p_stats["by_task_type"][task_type]
                    success_rate = task_stats["success"] / task_stats["count"]
                    
                    # ç»¼åˆè¯„åˆ†ï¼šæˆåŠŸç‡ * 0.7 + é€Ÿåº¦ * 0.3
                    speed_score = 1 / (p_stats["avg_duration"] + 1)
                    score = success_rate * 0.7 + speed_score * 0.3
                    
                    if score > best_score:
                        best_score = score
                        best_provider = provider
            
            if best_provider:
                return best_provider
        
        # å¦åˆ™æŒ‰æ•´ä½“æˆåŠŸç‡é€‰æ‹©
        best_provider = max(stats.items(), key=lambda x: x[1]["success_rate"])
        return best_provider[0]
    
    # ========== 2. Playbook æ•ˆæœå­¦ä¹  ==========
    
    def record_playbook_execution(
        self,
        playbook_id: str,
        success: bool,
        duration: float,
        event_type: str
    ):
        """
        è®°å½• Playbook æ‰§è¡Œç»“æœ
        
        Args:
            playbook_id: Playbook ID
            success: æ˜¯å¦æˆåŠŸ
            duration: æ‰§è¡Œæ—¶é•¿
            event_type: äº‹ä»¶ç±»å‹
        """
        stats = self._load_playbook_stats()
        
        if playbook_id not in stats:
            stats[playbook_id] = {
                "total_executions": 0,
                "success_count": 0,
                "fail_count": 0,
                "avg_duration": 0,
                "success_rate": 0,
                "last_success": None,
                "last_fail": None
            }
        
        p = stats[playbook_id]
        p["total_executions"] += 1
        
        if success:
            p["success_count"] += 1
            p["last_success"] = datetime.now().isoformat()
        else:
            p["fail_count"] += 1
            p["last_fail"] = datetime.now().isoformat()
        
        # æ›´æ–°å¹³å‡æ—¶é•¿ï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰
        alpha = 0.3
        if p["avg_duration"] == 0:
            p["avg_duration"] = duration
        else:
            p["avg_duration"] = alpha * duration + (1 - alpha) * p["avg_duration"]
        
        p["success_rate"] = p["success_count"] / p["total_executions"]
        
        self._save_playbook_stats(stats)
    
    def get_playbook_recommendations(self, min_executions: int = 5) -> List[Dict]:
        """
        è·å– Playbook æ¨èï¼ˆå“ªäº›è¯¥å¯ç”¨/ç¦ç”¨ï¼‰
        
        Args:
            min_executions: æœ€å°æ‰§è¡Œæ¬¡æ•°
        
        Returns:
            æ¨èåˆ—è¡¨
        """
        stats = self._load_playbook_stats()
        recommendations = []
        
        for playbook_id, p_stats in stats.items():
            if p_stats["total_executions"] < min_executions:
                continue
            
            # æˆåŠŸç‡ä½äº 30% â†’ å»ºè®®ç¦ç”¨
            if p_stats["success_rate"] < 0.3:
                recommendations.append({
                    "playbook_id": playbook_id,
                    "action": "disable",
                    "reason": f"Low success rate: {p_stats['success_rate']:.1%}",
                    "stats": p_stats
                })
            
            # æˆåŠŸç‡é«˜äº 80% â†’ å»ºè®®ä¿æŒå¯ç”¨
            elif p_stats["success_rate"] > 0.8:
                recommendations.append({
                    "playbook_id": playbook_id,
                    "action": "keep_enabled",
                    "reason": f"High success rate: {p_stats['success_rate']:.1%}",
                    "stats": p_stats
                })
        
        return recommendations
    
    # ========== 3. ä»»åŠ¡è·¯ç”±å­¦ä¹  ==========
    
    def record_task_routing(
        self,
        task_type: str,
        agent_template: str,
        success: bool,
        duration: float
    ):
        """
        è®°å½•ä»»åŠ¡è·¯ç”±ç»“æœ
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹
            agent_template: Agent æ¨¡æ¿
            success: æ˜¯å¦æˆåŠŸ
            duration: æ‰§è¡Œæ—¶é•¿
        """
        routing = self._load_task_routing()
        
        if task_type not in routing:
            routing[task_type] = {}
        
        if agent_template not in routing[task_type]:
            routing[task_type][agent_template] = {
                "count": 0,
                "success": 0,
                "fail": 0,
                "avg_duration": 0
            }
        
        r = routing[task_type][agent_template]
        r["count"] += 1
        
        if success:
            r["success"] += 1
        else:
            r["fail"] += 1
        
        # æ›´æ–°å¹³å‡æ—¶é•¿
        alpha = 0.3
        if r["avg_duration"] == 0:
            r["avg_duration"] = duration
        else:
            r["avg_duration"] = alpha * duration + (1 - alpha) * r["avg_duration"]
        
        self._save_task_routing(routing)
    
    def get_best_agent_template(self, task_type: str) -> str:
        """
        è·å–æœ€ä½³ Agent æ¨¡æ¿
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹
        
        Returns:
            æœ€ä½³ Agent æ¨¡æ¿
        """
        routing = self._load_task_routing()
        
        if task_type not in routing:
            return "monitor"  # é»˜è®¤
        
        # é€‰æ‹©æˆåŠŸç‡æœ€é«˜çš„
        best_template = max(
            routing[task_type].items(),
            key=lambda x: x[1]["success"] / x[1]["count"] if x[1]["count"] > 0 else 0
        )
        
        return best_template[0]
    
    # ========== 4. èµ„æºé˜ˆå€¼å­¦ä¹  ==========
    
    def record_threshold_event(
        self,
        resource_type: str,
        value: float,
        threshold: float,
        triggered_action: bool,
        was_necessary: bool = None
    ):
        """
        è®°å½•é˜ˆå€¼äº‹ä»¶
        
        Args:
            resource_type: èµ„æºç±»å‹ï¼ˆcpu/memory/gpuï¼‰
            value: å®é™…å€¼
            threshold: é˜ˆå€¼
            triggered_action: æ˜¯å¦è§¦å‘äº†åŠ¨ä½œ
            was_necessary: åŠ¨ä½œæ˜¯å¦å¿…è¦ï¼ˆç”¨æˆ·åé¦ˆï¼‰
        """
        event = {
            "timestamp": datetime.now().isoformat(),
            "resource_type": resource_type,
            "value": value,
            "threshold": threshold,
            "triggered_action": triggered_action,
            "was_necessary": was_necessary
        }
        
        with open(self.threshold_history_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(event, ensure_ascii=False) + "\n")
    
    def suggest_threshold_adjustment(self, resource_type: str) -> Dict:
        """
        å»ºè®®é˜ˆå€¼è°ƒæ•´
        
        Args:
            resource_type: èµ„æºç±»å‹
        
        Returns:
            è°ƒæ•´å»ºè®®
        """
        if not self.threshold_history_file.exists():
            return {"suggestion": "no_data"}
        
        # è¯»å–æœ€è¿‘ 30 å¤©çš„æ•°æ®
        cutoff = datetime.now() - timedelta(days=30)
        events = []
        
        with open(self.threshold_history_file, "r", encoding="utf-8") as f:
            for line in f:
                event = json.loads(line)
                if event["resource_type"] == resource_type:
                    event_time = datetime.fromisoformat(event["timestamp"])
                    if event_time >= cutoff:
                        events.append(event)
        
        if len(events) < 10:
            return {"suggestion": "insufficient_data"}
        
        # åˆ†æè¯¯æŠ¥ç‡
        false_positives = sum(
            1 for e in events
            if e["triggered_action"] and e.get("was_necessary") == False
        )
        
        false_positive_rate = false_positives / len(events) if events else 0
        
        # å¦‚æœè¯¯æŠ¥ç‡é«˜ï¼Œå»ºè®®æé«˜é˜ˆå€¼
        if false_positive_rate > 0.3:
            avg_value = sum(e["value"] for e in events) / len(events)
            current_threshold = events[0]["threshold"]
            suggested_threshold = avg_value * 1.1
            
            return {
                "suggestion": "increase_threshold",
                "current": current_threshold,
                "suggested": suggested_threshold,
                "reason": f"High false positive rate: {false_positive_rate:.1%}"
            }
        
        return {"suggestion": "keep_current"}
    
    # ========== 5. ç”¨æˆ·åé¦ˆå­¦ä¹  ==========
    
    def record_user_feedback(
        self,
        action_id: str,
        feedback: str,
        rating: int = None,
        comment: str = None
    ):
        """
        è®°å½•ç”¨æˆ·åé¦ˆ
        
        Args:
            action_id: åŠ¨ä½œ ID
            feedback: åé¦ˆç±»å‹ï¼ˆhelpful/not_helpful/wrongï¼‰
            rating: è¯„åˆ†ï¼ˆ1-5ï¼‰
            comment: è¯„è®º
        """
        feedback_entry = {
            "timestamp": datetime.now().isoformat(),
            "action_id": action_id,
            "feedback": feedback,
            "rating": rating,
            "comment": comment
        }
        
        with open(self.user_feedback_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(feedback_entry, ensure_ascii=False) + "\n")
    
    # ========== è¾…åŠ©æ–¹æ³• ==========
    
    def _load_provider_stats(self) -> Dict:
        """åŠ è½½ Provider ç»Ÿè®¡"""
        if not self.provider_stats_file.exists():
            return {}
        
        with open(self.provider_stats_file, "r", encoding="utf-8") as f:
            return json.load(f)
    
    def _save_provider_stats(self, stats: Dict):
        """ä¿å­˜ Provider ç»Ÿè®¡"""
        with open(self.provider_stats_file, "w", encoding="utf-8") as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
    
    def _load_playbook_stats(self) -> Dict:
        """åŠ è½½ Playbook ç»Ÿè®¡"""
        if not self.playbook_stats_file.exists():
            return {}
        
        with open(self.playbook_stats_file, "r", encoding="utf-8") as f:
            return json.load(f)
    
    def _save_playbook_stats(self, stats: Dict):
        """ä¿å­˜ Playbook ç»Ÿè®¡"""
        with open(self.playbook_stats_file, "w", encoding="utf-8") as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
    
    def _load_task_routing(self) -> Dict:
        """åŠ è½½ä»»åŠ¡è·¯ç”±"""
        if not self.task_routing_file.exists():
            return {}
        
        with open(self.task_routing_file, "r", encoding="utf-8") as f:
            return json.load(f)
    
    def _save_task_routing(self, routing: Dict):
        """ä¿å­˜ä»»åŠ¡è·¯ç”±"""
        with open(self.task_routing_file, "w", encoding="utf-8") as f:
            json.dump(routing, f, indent=2, ensure_ascii=False)
    
    def generate_learning_report(self) -> str:
        """ç”Ÿæˆå­¦ä¹ æŠ¥å‘Š"""
        report = []
        report.append("=" * 60)
        report.append("AIOS è‡ªå­¦ä¹ æŠ¥å‘Š")
        report.append("=" * 60)
        
        # Provider æ€§èƒ½
        provider_stats = self._load_provider_stats()
        if provider_stats:
            report.append("\nğŸ“Š Provider æ€§èƒ½:")
            for provider, stats in sorted(
                provider_stats.items(),
                key=lambda x: x[1]["success_rate"],
                reverse=True
            ):
                report.append(
                    f"  {provider}: "
                    f"æˆåŠŸç‡ {stats['success_rate']:.1%}, "
                    f"å¹³å‡æ—¶é•¿ {stats['avg_duration']:.2f}s, "
                    f"æ‰§è¡Œ {stats['total_executions']} æ¬¡"
                )
        
        # Playbook æ¨è
        recommendations = self.get_playbook_recommendations()
        if recommendations:
            report.append("\nğŸ’¡ Playbook æ¨è:")
            for rec in recommendations[:5]:
                report.append(f"  {rec['playbook_id']}: {rec['action']} - {rec['reason']}")
        
        # ä»»åŠ¡è·¯ç”±
        routing = self._load_task_routing()
        if routing:
            report.append("\nğŸ¯ ä»»åŠ¡è·¯ç”±å­¦ä¹ :")
            for task_type, agents in routing.items():
                best = max(agents.items(), key=lambda x: x[1]["success"] / x[1]["count"])
                report.append(
                    f"  {task_type} â†’ {best[0]} "
                    f"(æˆåŠŸç‡ {best[1]['success'] / best[1]['count']:.1%})"
                )
        
        report.append("\n" + "=" * 60)
        
        return "\n".join(report)


# å…¨å±€å•ä¾‹
_global_workflow: LearningWorkflow = None


def get_learning_workflow() -> LearningWorkflow:
    """è·å–å…¨å±€å­¦ä¹ å·¥ä½œæµå®ä¾‹"""
    global _global_workflow
    if _global_workflow is None:
        _global_workflow = LearningWorkflow()
    return _global_workflow
