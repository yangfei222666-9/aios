# AIOS v0.6 Backlog
**创建时间：** 2026-02-24 00:15  
**基于：** v0.5 优化分析报告  
**目标：** 从"玩具版"到"生产级"

---

## 背景

AIOS v0.5 已完成基础架构验证，集成测试全部通过（16/16 ✅）。当前是 proof of concept，核心组件都是 100-200 行代码。

**分析来源：**
- 分析者：小九（直接代码审查）
- 分析时间：2026-02-24 00:07-00:15
- 分析方法：读取 toy_scheduler.py / toy_reactor.py / toy_score_engine.py 源码 + 数据文件大小统计
- 完整报告：`aios/OPTIMIZATION_REPORT.md`

**当前状态：**
- 事件存储：events.jsonl 46KB（会无限增长）
- Scheduler：简单 if/else，无优先级队列
- Reactor：线性匹配（O(n)），只有 3 条规则
- ScoreEngine：固定权重，不能自学习
- 成功率：~77%（基于压力测试）

---

## P0 - 必须做（影响可用性）

### 1. 事件存储优化
**问题：** events.jsonl 会无限增长，最终导致内存溢出

**方案：**
```
aios/data/events/
  2026-02-24.jsonl      # 今天
  2026-02-23.jsonl      # 昨天
  archive/
    2026-02-01.jsonl.gz # 压缩归档
```

**清理策略：**
- 保留最近 7 天原始文件
- 7-30 天压缩存储
- 30 天以上删除（可选保留摘要）

**预期收益：**
- 内存占用降低 90%+
- 加载速度提升 10x
- 磁盘空间节省 80%+

**工作量：** 2-3 小时  
**优先级：** P0  
**风险：** 低（只改存储，不改逻辑）

---

### 2. Scheduler 优先级队列
**问题：** 当前是简单 if/else，无法处理并发和优先级

**方案：**
```python
class ProductionScheduler:
    def __init__(self):
        self.queue = PriorityQueue()
        self.running_tasks = {}
        self.max_concurrent = 5
    
    def _calculate_priority(self, event):
        # P0: 系统降级（score < 0.3）
        # P1: 资源告警（CPU/内存峰值）
        # P2: Agent 错误
        # P3: 正常事件
        ...
```

**预期收益：**
- 支持并发处理（5 个任务同时跑）
- 关键事件优先处理
- 避免队列堆积

**工作量：** 4-6 小时  
**优先级：** P0  
**风险：** 中（改调度逻辑，需要充分测试）

---

### 3. Reactor 规则索引
**问题：** 线性匹配 playbook（O(n)），100 条规则就慢了

**方案：**
```python
class ProductionReactor:
    def __init__(self):
        # 按事件类型索引
        self.playbook_index = {
            "resource.cpu_spike": [playbook1, playbook2],
            "resource.memory_high": [playbook3],
            "agent.error": [playbook4, playbook5],
        }
    
    def _match_playbook(self, event):
        # O(1) 查找
        candidates = self.playbook_index.get(event.type, [])
        return candidates[0] if candidates else None
```

**预期收益：**
- 匹配速度从 O(n) 降到 O(1)
- 支持 100+ playbook 规则
- 自动选择最佳匹配

**工作量：** 2-3 小时  
**优先级：** P0  
**风险：** 低（只改查找，不改匹配）

---

## P1 - 应该做（提升可靠性）

### 4. Skill 标准化接口（新增）
**问题：** 每个 Skill 输出格式不统一，Agent 难以判断成功/失败

**方案：**
```python
# aios/skills/base.py
class SkillResult:
    def __init__(self, ok: bool, result: dict, evidence: list, next_actions: list):
        self.ok = ok          # 成功/失败
        self.result = result  # 执行结果
        self.evidence = evidence  # 证据（log_path、metrics、diff、url）
        self.next = next_actions  # 下一步（retry、fallback、human_check）
    
    def to_dict(self):
        return {
            "ok": self.ok,
            "result": self.result,
            "evidence": self.evidence,
            "next": self.next
        }

class BaseSkill:
    def execute(self, params: dict) -> SkillResult:
        raise NotImplementedError

# 三类 Skill
# A. 观测类 (Observe): read_logs, metrics_snapshot, health_check
# B. 执行类 (Act): run_job, apply_patch, restart_service
# C. 验证类 (Verify): smoke_test, regression_test, performance_test
```

**Reactor 自动处理：**
```python
result = skill.execute(params)

if not result.ok:
    if "retry" in result.next:
        scheduler.schedule_retry(task)
    elif "fallback" in result.next:
        reactor.execute_fallback(playbook)
    elif "human_check" in result.next:
        notify("需要人工介入", result.evidence)
```

**预期收益：**
- 统一接口，降低集成成本
- Agent 看到 `ok=false` 立刻知道失败
- 自动按策略处理（重试/切换/进DLQ）
- 可追溯（evidence 记录所有证据）

**工作量：** 4-6 小时  
**优先级：** P1  
**风险：** 中（需要改造所有现有 Playbook）

---

### 5. ScoreEngine 权重自学习
**问题：** 固定权重（success_rate * 0.4 + ...）不一定适合真实场景

**方案：**
```python
class AdaptiveScoreEngine:
    def __init__(self):
        self.weights = {
            "success_rate": 0.4,
            "latency": 0.2,
            "stability": 0.2,
            "resource": 0.2
        }
    
    def adjust_weights(self, feedback):
        # 每周根据真实数据调整
        # 如果 latency 经常导致降级，增加权重
        ...
```

**预期收益：**
- 评分更准确
- 减少误报
- 自动适应不同场景

**工作量：** 4-6 小时  
**优先级：** P1  
**风险：** 中（可能导致评分不稳定）

---

### 5. 超时和重试机制
**问题：** Reactor 执行没有超时保护，playbook 卡住会一直等

**方案：**
```python
class ProductionReactor:
    def _execute_fix(self, playbook):
        # 超时保护
        with timeout(30):  # 30 秒超时
            result = self._run_playbook(playbook)
        
        # 失败重试（指数退避）
        if not result.success:
            for retry in range(3):
                time.sleep(2 ** retry)  # 2s, 4s, 8s
                result = self._run_playbook(playbook)
                if result.success:
                    break
```

**预期收益：**
- 避免卡死
- 提高成功率
- 更可靠

**工作量：** 2-3 小时  
**优先级：** P1  
**风险：** 低

---

### 6. 回滚机制
**问题：** Reactor 执行失败，没有办法回滚

**方案：**
```python
class ProductionReactor:
    def _execute_fix(self, playbook):
        # 执行前快照
        snapshot = self._create_snapshot()
        
        try:
            result = self._run_playbook(playbook)
            if not result.success:
                self._restore_snapshot(snapshot)
        except Exception as e:
            self._restore_snapshot(snapshot)
```

**预期收益：**
- 安全性提升
- 减少误操作影响
- 可审计

**工作量：** 4-6 小时  
**优先级：** P1  
**风险：** 高（可能引入新 bug）

---

## P2 - 可选（锦上添花）

### 7. Agent 架构优化（新增）
**问题：** 6个 Agent 功能重叠，通信复杂

**方案：**
- **观察期**：先跑 3-7 天，积累真实数据
- **数据驱动**：根据实际使用情况决定是否重构

**可能的优化方向：**
1. **合并 Agent**：6个 → 3个（Observer、Actor、Learner）
2. **引入 EventBus**：替代文件通信，实时响应
3. **状态管理**：可恢复、可追溯
4. **自适应机制**：根据环境调整策略
5. **可观测性**：指标、日志、追踪
6. **安全机制**：权限、审计、风险控制
7. **性能优化**：缓存、增量、并发
8. **测试框架**：单元测试、集成测试
9. **插件系统**：动态加载、热更新
10. **协作模式**：Pipeline、Parallel、Hierarchical

**决策标准：**
- 如果 6个 Agent 都有用 → 保持现状，优化性能
- 如果有些 Agent 没用 → 合并或删除
- 如果通信是瓶颈 → 引入 EventBus
- 如果状态管理是问题 → 引入状态机

**工作量：** 10-15 小时（大重构）  
**优先级：** P2（观察后再决定）  
**风险：** 高（可能引入新 bug）

---

### 8. Pixel Agents 可视化
**灵感：** Pixel Agents 项目（抖音 @DobbyAi）

**方案：**
- 像素风虚拟办公室
- Agent 状态可视化（idle/running/degraded/learning）
- 多 Agent 协作可视化

**工作量：** 8-10 小时  
**优先级：** P2  
**风险：** 低

---

### 8. Dashboard 实时推送优化
**方案：**
- 批量推送（攒够 10 个事件或 5 秒）
- 事件过滤（只推送重要事件）
- 增量更新

**工作量：** 2-3 小时  
**优先级：** P2  
**风险：** 低

---

### 9. Pipeline DAG 化
**方案：**
```python
pipeline = Pipeline()
pipeline.add_task("sensor_scan", depends_on=[])
pipeline.add_task("alert_check", depends_on=["sensor_scan"])
pipeline.add_task("reactor_trigger", depends_on=["alert_check"])
pipeline.run()
```

**工作量：** 6-8 小时  
**优先级：** P2  
**风险：** 高（大改架构）

---

### 10. 混沌测试
**方案：**
- 随机杀进程
- 随机网络延迟
- 随机磁盘满
- 随机 CPU 峰值

**工作量：** 4-6 小时  
**优先级：** P2  
**风险：** 低

---

## 实施计划

### Week 1（P0）
- [ ] 事件存储优化（2-3h）
- [ ] Scheduler 优先级队列（4-6h）
- [ ] Reactor 规则索引（2-3h）

**预期收益：**
- 内存占用降低 90%
- 并发处理能力提升 5x
- 匹配速度提升 10x

### Week 2（P1）
- [ ] ScoreEngine 权重自学习（4-6h）
- [ ] 超时和重试机制（2-3h）
- [ ] 回滚机制（4-6h）

**预期收益：**
- 评分准确性提升 30%
- 成功率提升 20%
- 安全性提升 50%

### Week 3（P2，可选）
- [ ] Pixel Agents 可视化（8-10h）
- [ ] Dashboard 实时推送优化（2-3h）
- [ ] Pipeline DAG 化（6-8h）
- [ ] 混沌测试（4-6h）

---

## 关键指标

**优化前（v0.5）：**
- 事件处理延迟：~100ms
- 内存占用：~50MB（会持续增长）
- 并发能力：1 个任务
- Playbook 匹配：O(n) 线性
- 成功率：~77%

**优化后（v0.6 预期）：**
- 事件处理延迟：~50ms（提升 2x）
- 内存占用：~10MB（降低 80%）
- 并发能力：5 个任务（提升 5x）
- Playbook 匹配：O(1) 常数
- 成功率：~90%+（提升 13%）

---

## 风险评估

**低风险：**
- 事件存储优化
- Reactor 规则索引
- 超时和重试机制
- Dashboard 优化
- 混沌测试

**中风险：**
- Scheduler 优先级队列
- ScoreEngine 权重自学习

**高风险：**
- 回滚机制
- Pipeline DAG 化

**建议：**
- 先做低风险优化，积累信心
- 中风险优化要有充分测试
- 高风险优化要有回滚预案

---

## 决策原则

1. **保持轻量** - 不引入重依赖
2. **向后兼容** - 不破坏现有 API
3. **测试驱动** - 所有改动必须有测试
4. **渐进式升级** - 先做低风险，再做高风险
5. **数据驱动** - 先观察几天，根据真实痛点优化

---

## 下一步

**选项 A：立即开始 P0**
- 优点：快速提升可用性
- 缺点：可能过度设计（没有真实数据验证）

**选项 B：观察 3-7 天，积累数据**
- 优点：基于真实痛点优化
- 缺点：可能遇到性能问题

**建议：选项 B**
- 先跑 3-7 天，积累真实数据
- 每天运行 `aios/scripts/daily_analysis.py` 查看趋势
- 根据数据决定优先级

---

**总计时间：** 7-10 天完成 v0.6 生产级升级

**成功标准：**
- 修复成功率：77% → 90%+
- 降级次数：3次/天 → 1次/天
- 误报减少，人工干预减少
