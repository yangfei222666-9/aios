#!/usr/bin/env python3
"""
AIOS å¿ƒè·³è¿è¡Œå™¨ v3.5
è‡ªåŠ¨å¤„ç†ä»»åŠ¡é˜Ÿåˆ—ã€æ¿€æ´»ä¼‘çœ Agentã€ä¿®å¤å¤±è´¥Agent
"""
import json
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ è·¯å¾„
WORKSPACE = Path(__file__).parent.parent.parent
sys.path.insert(0, str(WORKSPACE / "aios" / "agent_system"))

from learning_agents import LEARNING_AGENTS

# æ–‡ä»¶è·¯å¾„
TASK_QUEUE = Path(__file__).parent / "task_queue.jsonl"
SPAWN_REQUESTS = Path(__file__).parent / "spawn_requests.jsonl"
SPAWN_RESULTS = Path(__file__).parent / "spawn_results.jsonl"
AGENTS_FILE = Path(__file__).parent / "data" / "agents.json"
AGENTS_DATA_FILE = Path(__file__).parent / "agents_data.json"
STATE_FILE = WORKSPACE / "memory" / "selflearn-state.json"
HEARTBEAT_LOG = Path(__file__).parent / "heartbeat.log"
HEARTBEAT_STATS = Path(__file__).parent / "heartbeat_stats.json"

def log(message):
    """è®°å½•æ—¥å¿—"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] {message}"
    print(log_entry)
    
    # å†™å…¥æ—¥å¿—æ–‡ä»¶
    with open(HEARTBEAT_LOG, "a", encoding="utf-8") as f:
        f.write(log_entry + "\n")

def load_json(file_path):
    """åŠ è½½JSONæ–‡ä»¶"""
    if file_path.exists():
        with open(file_path, encoding="utf-8") as f:
            return json.load(f)
    return {}

def save_json(file_path, data):
    """ä¿å­˜JSONæ–‡ä»¶"""
    file_path.parent.mkdir(parents=True, exist_ok=True)
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

def load_jsonl(file_path):
    """åŠ è½½JSONLæ–‡ä»¶"""
    if not file_path.exists():
        return []
    with open(file_path, encoding="utf-8") as f:
        return [json.loads(line) for line in f if line.strip()]

def append_jsonl(file_path, data):
    """è¿½åŠ åˆ°JSONLæ–‡ä»¶"""
    with open(file_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(data, ensure_ascii=False) + "\n")

def process_task_queue():
    """å¤„ç†ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæ ¸å¿ƒå‡½æ•°ï¼‰"""
    log("ğŸ“‹ å¤„ç†ä»»åŠ¡é˜Ÿåˆ—...")
    
    # è¯»å–é˜Ÿåˆ—
    tasks = load_jsonl(TASK_QUEUE)
    if not tasks:
        log("  é˜Ÿåˆ—ä¸ºç©º")
        return "QUEUE_OK"
    
    log(f"  é˜Ÿåˆ—ä¸­æœ‰ {len(tasks)} ä¸ªä»»åŠ¡")
    
    # æœ€å¤šå¤„ç†5ä¸ª
    to_process = tasks[:5]
    remaining = tasks[5:]
    
    # è·¯ç”±æ˜ å°„ï¼ˆç›´æ¥æ˜ å°„åˆ° agents.json é‡Œçš„ Agentï¼‰
    route_map = {
        "code": "skill_creator",  # ä»£ç ç›¸å…³ â†’ skill_creator
        "analysis": "document_agent",  # åˆ†æç›¸å…³ â†’ document_agent
        "monitor": "aios_health_check",  # ç›‘æ§ç›¸å…³ â†’ aios_health_check
        "research": "document_agent"  # ç ”ç©¶ç›¸å…³ â†’ document_agent
    }
    
    processed = 0
    failed = 0
    stats = {}
    
    for task in to_process:
        task_id = task.get("id", "unknown")
        task_type = task.get("task_type", task.get("type", "unknown"))  # å…¼å®¹ä¸¤ç§æ ¼å¼
        agent_id = route_map.get(task_type, "document_agent")  # é»˜è®¤ç”¨ document_agent
        
        log(f"  å¤„ç†ä»»åŠ¡ {task_id} ({task_type}) -> {agent_id}")
        
        # åˆ›å»ºspawnè¯·æ±‚
        spawn_request = {
            "task_id": task_id,
            "task_type": task_type,
            "agent_id": agent_id,
            "description": task.get("description", ""),
            "priority": task.get("priority", "normal"),
            "created_at": datetime.now().isoformat(),
            "status": "pending"
        }
        
        try:
            # å†™å…¥spawnè¯·æ±‚
            append_jsonl(SPAWN_REQUESTS, spawn_request)
            
            # è®°å½•ç»“æœ
            result = {
                "task_id": task_id,
                "agent_id": agent_id,
                "status": "spawned",
                "spawned_at": datetime.now().isoformat()
            }
            append_jsonl(SPAWN_RESULTS, result)
            
            processed += 1
            stats[task_type] = stats.get(task_type, 0) + 1
            log(f"    âœ“ å·²åˆ›å»ºspawnè¯·æ±‚")
            
        except Exception as e:
            failed += 1
            log(f"    âœ— å¤±è´¥: {e}")
    
    # æ›´æ–°é˜Ÿåˆ—ï¼ˆç§»é™¤å·²å¤„ç†çš„ä»»åŠ¡ï¼‰
    if remaining:
        with open(TASK_QUEUE, "w", encoding="utf-8") as f:
            for task in remaining:
                f.write(json.dumps(task, ensure_ascii=False) + "\n")
    else:
        # æ¸…ç©ºé˜Ÿåˆ—
        TASK_QUEUE.unlink(missing_ok=True)
    
    # è¿”å›ç»“æœ
    if processed > 0:
        stats_str = ", ".join(f"{k}:{v}" for k, v in stats.items())
        return f"QUEUE_PROCESSED:{processed} ({stats_str})"
    elif failed > 0:
        return f"QUEUE_FAILED:{failed}"
    else:
        return "QUEUE_OK"

def activate_sleeping_learning_agents():
    """æ¿€æ´»ä¼‘çœ çš„å­¦ä¹ Agent"""
    log("ğŸ˜´ æ£€æŸ¥ä¼‘çœ çš„å­¦ä¹ Agent...")
    
    # è¯»å–çŠ¶æ€
    state = load_json(STATE_FILE)
    
    # æ‰¾å‡ºä»æœªè¿è¡Œçš„Agent
    never_run = []
    for agent in LEARNING_AGENTS:
        name = agent["name"]
        last_run_key = f"last_{name.lower()}"
        if not state.get(last_run_key):
            never_run.append(agent)
    
    if not never_run:
        log("  æ‰€æœ‰å­¦ä¹ Agentéƒ½å·²è¿è¡Œè¿‡")
        return "LEARNING_AGENTS_OK"
    
    log(f"  å‘ç° {len(never_run)} ä¸ªä»æœªè¿è¡Œçš„Agent")
    
    # ä¸ºæ¯ä¸ªAgentåˆ›å»ºspawnè¯·æ±‚
    activated = []
    for agent in never_run:
        task = f"""ä½ æ˜¯ {agent['role']}ã€‚

**ç›®æ ‡ï¼š** {agent['goal']}

**èƒŒæ™¯ï¼š** {agent.get('backstory', '')}

**ä»»åŠ¡ï¼š**
{chr(10).join('- ' + t for t in agent.get('tasks', []))}

**è¦æ±‚ï¼š**
1. è®°å½•å­¦ä¹ å†…å®¹åˆ° memory/{datetime.now().strftime('%Y-%m-%d')}.md
2. æå–æ ¸å¿ƒæ€è·¯ï¼ˆä¸è¦åªæ˜¯ç½—åˆ—é¡¹ç›®ï¼‰
3. å¯¹æ¯”æˆ‘ä»¬çš„ AIOSï¼ˆä¼˜åŠ¿ã€ç¼ºå£ã€å¯å€Ÿé‰´ï¼‰
4. ç»™å‡ºå…·ä½“çš„æ”¹è¿›å»ºè®®ï¼ˆå¯æ‰§è¡Œçš„ï¼‰
"""

        request = {
            "agent_name": agent["name"],
            "task": task,
            "model": agent.get("model", "claude-sonnet-4-6"),
            "thinking": agent.get("thinking", "off"),
            "priority": agent.get("priority", "normal"),
            "created_at": datetime.now().isoformat()
        }

        append_jsonl(SPAWN_REQUESTS, request)
        
        # æ›´æ–°çŠ¶æ€
        state[f"last_{agent['name'].lower()}"] = datetime.now().isoformat()
        activated.append(agent["name"])
        log(f"    âœ“ {agent['name']}")
    
    # ä¿å­˜çŠ¶æ€
    save_json(STATE_FILE, state)
    
    return f"LEARNING_AGENTS_ACTIVATED:{len(activated)}"

def handle_coder_failure():
    """å¤„ç†Coderè¿ç»­å¤±è´¥"""
    log("ğŸ”§ æ£€æŸ¥CoderçŠ¶æ€...")
    
    # è¯»å–agents_data.jsonï¼ˆæ–°çš„åŠ¨æ€æ•°æ®ï¼‰
    agents_data = load_json(AGENTS_DATA_FILE)
    agents = agents_data.get("agents", [])
    
    # æ‰¾åˆ°æ´»è·ƒçš„coder-dispatcher
    coder = None
    for agent in agents:
        if agent.get("id") == "coder-dispatcher" and agent.get("status") == "active":
            coder = agent
            break
    
    if not coder:
        log("  æœªæ‰¾åˆ°æ´»è·ƒçš„coder-dispatcherï¼ˆå¯èƒ½å·²å½’æ¡£ï¼‰")
        return "CODER_OK"  # æ²¡æœ‰æ´»è·ƒçš„Coderï¼Œä¸éœ€è¦æ£€æŸ¥
    
    # æ£€æŸ¥å¤±è´¥æ¬¡æ•°
    stats = coder.get("stats", {})
    failed = stats.get("tasks_failed", 0)
    completed = stats.get("tasks_completed", 0)
    
    log(f"  Coderç»Ÿè®¡: å®Œæˆ{completed}, å¤±è´¥{failed}")
    
    if failed < 3:
        log("  Coderæ­£å¸¸")
        return "CODER_OK"
    
    # å¤±è´¥â‰¥3æ¬¡ï¼Œéœ€è¦ä¿®å¤
    log(f"  âš ï¸ Coderè¿ç»­å¤±è´¥{failed}æ¬¡ï¼Œåº”ç”¨ä¿®å¤...")
    
    # ä¿®å¤ç­–ç•¥
    fixes_applied = []
    
    # 1. å¢åŠ è¶…æ—¶
    if coder.get("timeout", 60) < 120:
        coder["timeout"] = 120
        fixes_applied.append("timeout:60â†’120")
        log("    âœ“ è¶…æ—¶å¢åŠ åˆ°120ç§’")
    
    # 2. é™ä½thinking level
    if coder.get("thinking") == "high":
        coder["thinking"] = "medium"
        fixes_applied.append("thinking:highâ†’medium")
        log("    âœ“ thinkingé™ä½åˆ°medium")
    
    # 3. å¢åŠ é‡è¯•æ¬¡æ•°
    if coder.get("max_retries", 3) < 5:
        coder["max_retries"] = 5
        fixes_applied.append("retries:3â†’5")
        log("    âœ“ é‡è¯•æ¬¡æ•°å¢åŠ åˆ°5")
    
    # ä¿å­˜ä¿®æ”¹
    if fixes_applied:
        save_json(AGENTS_FILE, agents_data)
        log(f"  âœ“ å·²åº”ç”¨ {len(fixes_applied)} ä¸ªä¿®å¤")
        return f"CODER_FIXED ({', '.join(fixes_applied)})"
    else:
        log("  âš ï¸ æ— æ³•è‡ªåŠ¨ä¿®å¤ï¼Œéœ€è¦äººå·¥ä»‹å…¥")
        return "CODER_NEEDS_ATTENTION"

def check_self_improving_loop():
    """æ£€æŸ¥Self-Improving Loop"""
    log("ğŸ”„ æ£€æŸ¥Self-Improving Loop...")
    
    # è¯»å–loopçŠ¶æ€
    loop_state_file = Path(__file__).parent / "data" / "loop_state.json"
    if not loop_state_file.exists():
        log("  LoopçŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨")
        return "LOOP_NOT_INITIALIZED"
    
    loop_state = load_json(loop_state_file)
    improvements = loop_state.get("total_improvements", 0)
    
    log(f"  æ€»æ”¹è¿›æ¬¡æ•°: {improvements}")
    
    if improvements > 0:
        return f"SELF_IMPROVING:+{improvements}"
    else:
        return "SELF_IMPROVING_OK"

def clean_temp_files():
    """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
    log("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
    
    # æ¸…ç†.bakæ–‡ä»¶
    bak_files = list(Path(__file__).parent.rglob("*.bak"))
    for f in bak_files:
        f.unlink()
    
    if bak_files:
        log(f"  âœ“ æ¸…ç†äº† {len(bak_files)} ä¸ª.bakæ–‡ä»¶")
    
    return "CLEANUP_OK"

def update_stats(results):
    """æ›´æ–°å¿ƒè·³ç»Ÿè®¡"""
    stats = load_json(HEARTBEAT_STATS)
    
    # åˆå§‹åŒ–
    if "total_heartbeats" not in stats:
        stats["total_heartbeats"] = 0
        stats["tasks_processed"] = 0
        stats["agents_activated"] = 0
        stats["coder_fixes"] = 0
    
    # æ›´æ–°
    stats["total_heartbeats"] += 1
    stats["last_heartbeat"] = datetime.now().isoformat()
    
    # è§£æç»“æœ
    for result in results:
        if result.startswith("QUEUE_PROCESSED:"):
            count = int(result.split(":")[1].split()[0])
            stats["tasks_processed"] += count
        elif result.startswith("LEARNING_AGENTS_ACTIVATED:"):
            count = int(result.split(":")[1])
            stats["agents_activated"] += count
        elif result.startswith("CODER_FIXED"):
            stats["coder_fixes"] += 1
    
    save_json(HEARTBEAT_STATS, stats)

def heartbeat():
    """å¿ƒè·³ä¸»å‡½æ•°"""
    log("=" * 80)
    log("ğŸš€ AIOS Heartbeat Started @ " + datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    log("=" * 80)
    
    results = []
    
    try:
        # 1. å¤„ç†ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæœ€ä¼˜å…ˆï¼‰
        result = process_task_queue()
        results.append(result)
        
        # 2. æ£€æŸ¥å¹¶å¯åŠ¨ä»æœªè¿è¡Œçš„å­¦ä¹ Agent
        result = activate_sleeping_learning_agents()
        results.append(result)
        
        # 3. å¤„ç† Coder è¿ç»­å¤±è´¥é—®é¢˜
        result = handle_coder_failure()
        results.append(result)
        
        # 4. Self-Improving Loop æ£€æŸ¥
        result = check_self_improving_loop()
        results.append(result)
        
        # 5. æ¸…ç† & è®°å½•
        result = clean_temp_files()
        results.append(result)
        
        # æ›´æ–°ç»Ÿè®¡
        update_stats(results)
        
        log("=" * 80)
        log("âœ… Heartbeat Completed")
        log("=" * 80)
        
        # è¾“å‡ºæ‘˜è¦
        summary = []
        for r in results:
            if not r.endswith("_OK"):
                summary.append(r)
        
        if summary:
            print("\n" + ", ".join(summary))
        else:
            print("\nHEARTBEAT_OK")
        
    except Exception as e:
        log(f"âŒ Heartbeatå¤±è´¥: {e}")
        import traceback
        log(traceback.format_exc())
        print(f"\nHEARTBEAT_ERROR: {e}")

if __name__ == "__main__":
    heartbeat()
