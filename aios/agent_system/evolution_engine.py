"""
Evolution Engine - Agent è‡ªè¿›åŒ–ç»Ÿä¸€å¼•æ“

å°†æ‰€æœ‰è¿›åŒ–èƒ½åŠ›æ•´åˆä¸ºä¸€ä¸ªå®Œæ•´é—­ç¯ï¼š

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                  Evolution Engine                     â”‚
  â”‚                                                       â”‚
  â”‚  1. Observe  â†’ æ”¶é›†è¿½è¸ªæ•°æ®ã€å¤±è´¥æ¨¡å¼                  â”‚
  â”‚  2. Analyze  â†’ è¯†åˆ« prompt ç¼ºé™·ã€ç­–ç•¥ç¼ºå£              â”‚
  â”‚  3. Learn    â†’ ç”Ÿæˆæ–°ç­–ç•¥ã€æå–æœ€ä½³å®è·µ                 â”‚
  â”‚  4. Evolve   â†’ ä¼˜åŒ– promptã€è°ƒæ•´é…ç½®                   â”‚
  â”‚  5. Verify   â†’ A/B æµ‹è¯•ã€æ•ˆæœè¯„ä¼°                      â”‚
  â”‚  6. Share    â†’ è·¨ Agent çŸ¥è¯†ä¼ æ’­                       â”‚
  â”‚                                                       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å®‰å…¨æœºåˆ¶ï¼š
- æ¯å¤©æœ€å¤šè¿›åŒ– 1 æ¬¡ï¼ˆper Agentï¼‰
- åªè‡ªåŠ¨åº”ç”¨ä½é£é™©æ”¹è¿›
- æ‰€æœ‰å˜æ›´å¯å›æ»š
- ä¸­é«˜é£é™©éœ€äººå·¥å®¡æ ¸
"""

import json
import time
import sys
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

# ç¡®ä¿èƒ½å¯¼å…¥åŒçº§æ¨¡å—
sys.path.insert(0, str(Path(__file__).resolve().parent))

from prompt_evolver import PromptEvolver
from strategy_learner import StrategyLearner
from cross_agent_learner import CrossAgentLearner
from evolution import AgentEvolution
from auto_evolution import AutoEvolution
from agent_tracer import TraceAnalyzer
from evolution_events import get_emitter
from core.agent_manager import AgentManager


class EvolutionEngine:
    """Agent è‡ªè¿›åŒ–ç»Ÿä¸€å¼•æ“"""

    # å®‰å…¨å¸¸é‡
    MAX_EVOLUTIONS_PER_DAY = 3      # å…¨å±€æ¯å¤©æœ€å¤šè¿›åŒ–æ¬¡æ•°
    EVOLUTION_INTERVAL_HOURS = 6    # ä¸¤æ¬¡è¿›åŒ–æœ€å°é—´éš”

    def __init__(self, data_dir: str = None):
        if data_dir is None:
            data_dir = Path.home() / ".openclaw" / "workspace" / "aios" / "agent_system" / "data"
        self.data_dir = Path(data_dir)

        # åˆå§‹åŒ–å­æ¨¡å—
        self.prompt_evolver = PromptEvolver(str(self.data_dir))
        self.strategy_learner = StrategyLearner(str(self.data_dir))
        self.cross_learner = CrossAgentLearner(str(self.data_dir))
        self.evolution = AgentEvolution(str(self.data_dir))
        self.auto_evolution = AutoEvolution(str(self.data_dir))
        self.agent_manager = AgentManager(str(self.data_dir))
        self.emitter = get_emitter()

        # çŠ¶æ€æ–‡ä»¶
        self.state_file = self.data_dir / "evolution" / "engine_state.json"
        self.report_dir = self.data_dir / "evolution" / "reports"
        self.report_dir.mkdir(parents=True, exist_ok=True)

    def run_full_cycle(self, dry_run: bool = False) -> Dict:
        """
        è¿è¡Œå®Œæ•´è¿›åŒ–å¾ªç¯

        Args:
            dry_run: æ˜¯å¦åªåˆ†æä¸åº”ç”¨

        Returns:
            è¿›åŒ–æŠ¥å‘Š
        """
        start_time = time.time()
        report = {
            "timestamp": datetime.now().isoformat(),
            "dry_run": dry_run,
            "phases": {},
            "summary": {}
        }

        print("=" * 60)
        print("  AIOS Evolution Engine - Full Cycle")
        print(f"  Mode: {'DRY RUN' if dry_run else 'LIVE'}")
        print(f"  Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)

        # Phase 1: Observe - æ”¶é›†æ•°æ®
        print("\n[Phase 1] Observe - æ”¶é›†è¿½è¸ªæ•°æ®...")
        observe_result = self._phase_observe()
        report["phases"]["observe"] = observe_result
        print(f"  è¿½è¸ªè®°å½•: {observe_result['total_traces']}")
        print(f"  å¤±è´¥æ¨¡å¼: {observe_result['failure_patterns']}")
        print(f"  æ´»è·ƒ Agent: {observe_result['active_agents']}")

        if observe_result["total_traces"] < 5:
            report["summary"] = {"status": "insufficient_data", "message": "æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è¿›åŒ–"}
            print("\nâš ï¸ æ•°æ®ä¸è¶³ï¼ˆ< 5 æ¡è¿½è¸ªï¼‰ï¼Œè·³è¿‡è¿›åŒ–")
            self._save_report(report)
            return report

        # Phase 2: Analyze - åˆ†æç¼ºé™·
        print("\n[Phase 2] Analyze - åˆ†æ Prompt ç¼ºé™·å’Œç­–ç•¥ç¼ºå£...")
        analyze_result = self._phase_analyze(observe_result)
        report["phases"]["analyze"] = analyze_result
        print(f"  Prompt ç¼ºé™·: {analyze_result['prompt_gaps']}")
        print(f"  ç­–ç•¥ç¼ºå£: {analyze_result['strategy_gaps']}")

        # Phase 3: Learn - å­¦ä¹ æ–°ç­–ç•¥
        print("\n[Phase 3] Learn - ä»ç»éªŒä¸­å­¦ä¹ ...")
        learn_result = self._phase_learn(observe_result)
        report["phases"]["learn"] = learn_result
        print(f"  æ–°ç­–ç•¥: {learn_result['new_strategies']}")
        print(f"  æœ€ä½³å®è·µ: {learn_result['best_practices']}")

        if dry_run:
            report["summary"] = {
                "status": "dry_run",
                "message": "åˆ†æå®Œæˆï¼ˆdry run æ¨¡å¼ï¼Œæœªåº”ç”¨å˜æ›´ï¼‰",
                "potential_changes": analyze_result["prompt_gaps"] + learn_result["new_strategies"]
            }
            print("\nğŸ“‹ Dry run å®Œæˆï¼Œæœªåº”ç”¨ä»»ä½•å˜æ›´")
            self._save_report(report)
            return report

        # Phase 4: Evolve - åº”ç”¨è¿›åŒ–
        print("\n[Phase 4] Evolve - åº”ç”¨è¿›åŒ–æ”¹è¿›...")
        evolve_result = self._phase_evolve(analyze_result, learn_result)
        report["phases"]["evolve"] = evolve_result
        print(f"  Prompt è¡¥ä¸: {evolve_result['prompts_patched']}")
        print(f"  é…ç½®è°ƒæ•´: {evolve_result['configs_adjusted']}")
        print(f"  ç­–ç•¥åˆå¹¶: {evolve_result['strategies_merged']}")

        # Phase 5: Share - è·¨ Agent ä¼ æ’­
        print("\n[Phase 5] Share - è·¨ Agent çŸ¥è¯†ä¼ æ’­...")
        share_result = self._phase_share()
        report["phases"]["share"] = share_result
        print(f"  çŸ¥è¯†ä¼ æ’­: {share_result['transfers']}")

        # æ€»ç»“
        total_changes = (
            evolve_result["prompts_patched"] +
            evolve_result["configs_adjusted"] +
            share_result["transfers"]
        )
        elapsed = time.time() - start_time

        report["summary"] = {
            "status": "evolved" if total_changes > 0 else "no_changes",
            "total_changes": total_changes,
            "elapsed_sec": round(elapsed, 2),
            "message": f"å®Œæˆ {total_changes} é¡¹æ”¹è¿›" if total_changes > 0 else "æ— éœ€æ”¹è¿›"
        }

        print("\n" + "=" * 60)
        print(f"  å®Œæˆï¼è€—æ—¶ {elapsed:.1f}sï¼Œå…± {total_changes} é¡¹æ”¹è¿›")
        print("=" * 60)

        self._save_report(report)
        return report

    def _phase_observe(self) -> Dict:
        """Phase 1: æ”¶é›†è¿½è¸ªæ•°æ®ï¼ˆåªçœ‹ prodï¼‰"""
        analyzer = TraceAnalyzer()
        traces = analyzer.traces

        # åªåˆ†æ prod ç¯å¢ƒçš„å¤±è´¥æ¨¡å¼
        failure_patterns = analyzer.get_failure_patterns(min_occurrences=3, env="prod")
        agents = self.agent_manager.list_agents(status="active")

        # æŒ‰ agent åˆ†ç»„ç»Ÿè®¡
        agent_stats = {}
        for agent in agents:
            stats = analyzer.get_agent_stats(agent["id"])
            if stats.get("total_tasks", 0) > 0:
                agent_stats[agent["id"]] = stats

        return {
            "total_traces": len(traces),
            "failure_patterns": len(failure_patterns),
            "failure_details": failure_patterns[:5],
            "active_agents": len(agents),
            "agent_stats": agent_stats,
            "traces": traces,  # ä¼ é€’ç»™åç»­é˜¶æ®µ
            "agents": agents
        }

    def _phase_analyze(self, observe_data: Dict) -> Dict:
        """Phase 2: åˆ†æç¼ºé™·"""
        prompt_gaps_total = 0
        strategy_gaps = 0
        agent_gaps = {}

        for agent in observe_data["agents"]:
            agent_id = agent["id"]
            stats = observe_data["agent_stats"].get(agent_id)
            if not stats:
                continue

            # è·å–è¯¥ Agent çš„å¤±è´¥è¿½è¸ª
            failure_traces = [
                t for t in observe_data["traces"]
                if t.get("agent_id") == agent_id and not t.get("success")
            ]

            if not failure_traces:
                continue

            # åˆ†æ prompt ç¼ºé™·
            gaps = self.prompt_evolver.analyze_prompt_gaps(agent_id, failure_traces)
            if gaps:
                agent_gaps[agent_id] = gaps
                prompt_gaps_total += len(gaps)

            # åˆ†æç­–ç•¥ç¼ºå£ï¼ˆé€šè¿‡ auto_evolution çš„è§¦å‘è¯„ä¼°ï¼‰
            analysis = self.evolution.analyze_failures(agent_id, lookback_hours=168)  # 7å¤©
            matched = self.auto_evolution.evaluate_triggers(agent_id, analysis)
            if matched:
                strategy_gaps += len(matched)

        return {
            "prompt_gaps": prompt_gaps_total,
            "strategy_gaps": strategy_gaps,
            "agent_gaps": agent_gaps
        }

    def _phase_learn(self, observe_data: Dict) -> Dict:
        """Phase 3: ä»ç»éªŒä¸­å­¦ä¹ """
        # å­¦ä¹ æ–°ç­–ç•¥
        new_strategies = self.strategy_learner.learn_from_traces(observe_data["traces"])

        # æå–æœ€ä½³å®è·µ
        all_practices = []
        for agent in observe_data["agents"]:
            agent_id = agent["id"]
            stats = observe_data["agent_stats"].get(agent_id)
            if not stats:
                continue

            practices = self.cross_learner.extract_best_practices(stats, agent)
            all_practices.extend(practices)

        # æ„å»ºçŸ¥è¯†åº“
        if all_practices:
            self.cross_learner.build_knowledge_base(all_practices)

        return {
            "new_strategies": len(new_strategies),
            "strategy_details": new_strategies,
            "best_practices": len(all_practices),
            "practice_details": all_practices[:10]
        }

    def _phase_evolve(self, analyze_data: Dict, learn_data: Dict) -> Dict:
        """Phase 4: åº”ç”¨è¿›åŒ–ï¼ˆå¸¦å½±å­éªŒè¯ï¼‰"""
        from shadow_validator import ShadowValidator
        
        validator = ShadowValidator(str(self.data_dir))
        prompts_patched = 0
        configs_adjusted = 0
        strategies_merged = 0
        validation_blocked = 0  # è¢«éªŒè¯æ‹¦æˆªçš„æ”¹è¿›æ•°

        # 4.1 åº”ç”¨ Prompt è¡¥ä¸ï¼ˆå¸¦éªŒè¯ï¼‰
        for agent_id, gaps in analyze_data.get("agent_gaps", {}).items():
            agent = self.agent_manager.get_agent(agent_id)
            if not agent:
                continue

            system_prompt = agent.get("system_prompt") or agent.get("role", "")
            patch = self.prompt_evolver.generate_prompt_patch(
                agent_id, system_prompt, gaps
            )
            if patch:
                # å½±å­éªŒè¯
                improvement = {
                    "type": "prompt_patch",
                    "patch": str(patch),
                    "reason": "ä¿®å¤ Prompt ç¼ºé™·"
                }
                ok, msg = validator.validate_before_apply(agent_id, improvement)
                
                if not ok:
                    print(f"  âš ï¸  {agent_id} Prompt è¡¥ä¸è¢«æ‹¦æˆª: {msg}")
                    validation_blocked += 1
                    self.emitter.emit_blocked(agent_id, improvement, msg)
                    continue
                
                success = self.prompt_evolver.apply_patch(agent_id, self.agent_manager, patch)
                if success:
                    prompts_patched += 1
                    self.emitter.emit_applied(agent_id, [{
                        "action": "prompt_evolution",
                        "description": f"è¿½åŠ  {len(patch['rules_added'])} æ¡è‡ªè¿›åŒ–è§„åˆ™",
                        "changes": {"rules_added": [r["rule"] for r in patch["rules_added"]]}
                    }])

        # 4.2 åˆå¹¶å­¦ä¹ åˆ°çš„ç­–ç•¥
        new_strategies = learn_data.get("strategy_details", [])
        if new_strategies:
            strategies_merged = self.strategy_learner.merge_to_strategy_library(new_strategies)

        # 4.3 é€šè¿‡ auto_evolution åº”ç”¨é…ç½®è°ƒæ•´ï¼ˆå¸¦éªŒè¯ï¼‰
        agents = self.agent_manager.list_agents(status="active")
        for agent in agents:
            result = self.auto_evolution.auto_evolve(agent["id"], self.agent_manager)
            if result.get("status") == "applied":
                # å¯¹æ¯ä¸ªæ”¹è¿›è®¡åˆ’éªŒè¯
                for plan in result.get("plans", []):
                    improvement = {
                        "type": "config_change",
                        "key": plan.get("key"),
                        "value": plan.get("value"),
                        "reason": plan.get("reason")
                    }
                    ok, msg = validator.validate_before_apply(agent["id"], improvement)
                    
                    if not ok:
                        print(f"  âš ï¸  {agent['id']} é…ç½®è°ƒæ•´è¢«æ‹¦æˆª: {msg}")
                        validation_blocked += 1
                        self.emitter.emit_blocked(agent["id"], improvement, msg)
                    else:
                        configs_adjusted += 1

        return {
            "prompts_patched": prompts_patched,
            "configs_adjusted": configs_adjusted,
            "strategies_merged": strategies_merged,
            "validation_blocked": validation_blocked  # æ–°å¢ï¼šè¢«æ‹¦æˆªæ•°
        }

    def _phase_share(self) -> Dict:
        """Phase 5: è·¨ Agent çŸ¥è¯†ä¼ æ’­"""
        transfers = 0
        agents = self.agent_manager.list_agents(status="active")

        for agent in agents:
            agent_id = agent["id"]
            stats = agent.get("stats", {})
            total = stats.get("tasks_completed", 0) + stats.get("tasks_failed", 0)
            success_rate = stats.get("success_rate", 0)

            # åªå¯¹ä½æˆåŠŸç‡ Agent ä¼ æ’­çŸ¥è¯†
            if total >= 5 and success_rate < 0.5:
                result = self.cross_learner.transfer_knowledge(
                    agent_id, agent, self.agent_manager
                )
                if result.get("status") == "transferred":
                    transfers += 1

        return {"transfers": transfers}

    def _save_report(self, report: Dict):
        """ä¿å­˜è¿›åŒ–æŠ¥å‘Š"""
        filename = f"evolution_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        report_path = self.report_dir / filename
        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

    def get_evolution_status(self) -> Dict:
        """è·å–è¿›åŒ–ç³»ç»ŸçŠ¶æ€"""
        agents = self.agent_manager.list_agents(status="active")
        knowledge_summary = self.cross_learner.get_knowledge_summary()

        # ç»Ÿè®¡è¿›åŒ–å†å²
        evolution_log = self.data_dir / "evolution" / "evolution_history.jsonl"
        total_evolutions = 0
        if evolution_log.exists():
            with open(evolution_log, "r", encoding="utf-8") as f:
                total_evolutions = sum(1 for line in f if line.strip())

        # ç»Ÿè®¡ prompt è¡¥ä¸
        patches_file = self.data_dir / "evolution" / "prompts" / "prompt_patches.jsonl"
        total_patches = 0
        if patches_file.exists():
            with open(patches_file, "r", encoding="utf-8") as f:
                total_patches = sum(1 for line in f if line.strip())

        # åŠ è½½ç­–ç•¥åº“
        strategies_file = self.data_dir / "evolution" / "evolution_strategies.json"
        total_strategies = 0
        learned_strategies = 0
        if strategies_file.exists():
            with open(strategies_file, "r", encoding="utf-8") as f:
                strategies = json.load(f)
                total_strategies = len(strategies)
                learned_strategies = sum(
                    1 for s in strategies.values()
                    if s.get("source") == "strategy_learner"
                )

        return {
            "active_agents": len(agents),
            "total_evolutions": total_evolutions,
            "total_prompt_patches": total_patches,
            "total_strategies": total_strategies,
            "learned_strategies": learned_strategies,
            "knowledge_base": knowledge_summary,
            "last_check": datetime.now().isoformat()
        }


def main():
    """CLI å…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description="AIOS Evolution Engine")
    parser.add_argument("command", choices=["run", "status", "dry-run"],
                        help="å‘½ä»¤ï¼šrun=æ‰§è¡Œè¿›åŒ–, status=æŸ¥çœ‹çŠ¶æ€, dry-run=åˆ†æä¸åº”ç”¨")
    args = parser.parse_args()

    engine = EvolutionEngine()

    if args.command == "run":
        result = engine.run_full_cycle(dry_run=False)
        status = result["summary"]["status"]
        if status == "evolved":
            print(f"\nEVOLUTION_APPLIED:{result['summary']['total_changes']}")
        else:
            print(f"\nEVOLUTION_OK")

    elif args.command == "dry-run":
        result = engine.run_full_cycle(dry_run=True)
        print(json.dumps(result["summary"], ensure_ascii=False, indent=2))

    elif args.command == "status":
        status = engine.get_evolution_status()
        print(json.dumps(status, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
