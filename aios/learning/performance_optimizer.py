#!/usr/bin/env python3
"""
AIOS è‡ªåŠ¨æ€§èƒ½ä¼˜åŒ–å™¨
ç›‘æ§ç³»ç»Ÿæ€§èƒ½ï¼Œè¯†åˆ«ç“¶é¢ˆï¼Œè‡ªåŠ¨åº”ç”¨ä½é£é™©ä¼˜åŒ–
"""

import os
import json
import time
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict

# é…ç½®
WORKSPACE = Path(__file__).parent.parent.parent
AIOS_DIR = WORKSPACE / "aios"
EVENTS_FILE = AIOS_DIR / "data" / "events.jsonl"
PERF_REPORT_FILE = AIOS_DIR / "data" / "performance_report.json"
OPTIMIZATION_LOG = AIOS_DIR / "data" / "optimizations.jsonl"

# æ€§èƒ½é˜ˆå€¼
SLOW_OPERATION_THRESHOLD = 5.0  # ç§’
HIGH_LATENCY_THRESHOLD = 3.0    # ç§’
FREQUENT_OPERATION_THRESHOLD = 10  # æ¬¡/å°æ—¶

# ä¼˜åŒ–ç­–ç•¥
OPTIMIZATIONS = {
    "reduce_heartbeat_frequency": {
        "risk": "low",
        "description": "é™ä½å¿ƒè·³é¢‘ç‡ï¼ˆ30min â†’ 45minï¼‰",
        "condition": lambda stats: stats.get('heartbeat_count', 0) > 20,
        "action": "update_heartbeat_interval",
        "params": {"interval_minutes": 45}
    },
    "increase_cache_ttl": {
        "risk": "low",
        "description": "å¢åŠ ç¼“å­˜TTLï¼ˆ5min â†’ 10minï¼‰",
        "condition": lambda stats: stats.get('cache_miss_rate', 0) > 0.5,
        "action": "update_cache_config",
        "params": {"ttl_minutes": 10}
    },
    "batch_event_writes": {
        "risk": "low",
        "description": "æ‰¹é‡å†™å…¥äº‹ä»¶ï¼ˆå‡å°‘ç£ç›˜I/Oï¼‰",
        "condition": lambda stats: stats.get('event_write_count', 0) > 100,
        "action": "enable_event_batching",
        "params": {"batch_size": 10}
    },
    "cleanup_idle_agents": {
        "risk": "low",
        "description": "æ¸…ç†é—²ç½®Agentï¼ˆ>1hæ— æ´»åŠ¨ï¼‰",
        "condition": lambda stats: stats.get('idle_agent_count', 0) > 3,
        "action": "cleanup_idle_agents",
        "params": {"idle_threshold_minutes": 60}
    },
}


def load_events(hours=1):
    """åŠ è½½æœ€è¿‘Nå°æ—¶çš„äº‹ä»¶"""
    if not EVENTS_FILE.exists():
        return []
    
    cutoff_time = datetime.now() - timedelta(hours=hours)
    events = []
    
    with open(EVENTS_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                event = json.loads(line)
                timestamp = event.get('timestamp', '')
                if not timestamp:
                    continue
                
                event_time = datetime.fromisoformat(timestamp)
                if event_time >= cutoff_time:
                    events.append(event)
            except (json.JSONDecodeError, ValueError, TypeError):
                continue
    
    return events


def analyze_performance(events):
    """åˆ†ææ€§èƒ½æ•°æ®"""
    stats = {
        "total_events": len(events),
        "slow_operations": [],
        "high_latency_operations": [],
        "frequent_operations": defaultdict(int),
        "heartbeat_count": 0,
        "event_write_count": 0,
        "cache_hits": 0,
        "cache_misses": 0,
        "idle_agent_count": 0,
    }
    
    for event in events:
        event_type = event.get('type', '')
        duration = event.get('duration', 0)
        operation = event.get('operation', '')
        
        # ç»Ÿè®¡æ…¢æ“ä½œ
        if duration > SLOW_OPERATION_THRESHOLD:
            stats['slow_operations'].append({
                "operation": operation,
                "duration": duration,
                "timestamp": event.get('timestamp')
            })
        
        # ç»Ÿè®¡é«˜å»¶è¿Ÿæ“ä½œ
        if duration > HIGH_LATENCY_THRESHOLD:
            stats['high_latency_operations'].append({
                "operation": operation,
                "duration": duration
            })
        
        # ç»Ÿè®¡é¢‘ç¹æ“ä½œ
        if operation:
            stats['frequent_operations'][operation] += 1
        
        # ç»Ÿè®¡ç‰¹å®šäº‹ä»¶
        if event_type == 'heartbeat':
            stats['heartbeat_count'] += 1
        elif event_type == 'event_write':
            stats['event_write_count'] += 1
        elif event_type == 'cache_hit':
            stats['cache_hits'] += 1
        elif event_type == 'cache_miss':
            stats['cache_misses'] += 1
        elif event_type == 'agent_idle':
            stats['idle_agent_count'] += 1
    
    # è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡
    total_cache_ops = stats['cache_hits'] + stats['cache_misses']
    if total_cache_ops > 0:
        stats['cache_miss_rate'] = stats['cache_misses'] / total_cache_ops
    else:
        stats['cache_miss_rate'] = 0
    
    return stats


def identify_bottlenecks(stats):
    """è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ"""
    bottlenecks = []
    
    # æ…¢æ“ä½œ
    if len(stats['slow_operations']) > 0:
        bottlenecks.append({
            "type": "slow_operations",
            "severity": "medium",
            "count": len(stats['slow_operations']),
            "details": stats['slow_operations'][:5]  # åªæ˜¾ç¤ºå‰5ä¸ª
        })
    
    # é«˜å»¶è¿Ÿæ“ä½œ
    if len(stats['high_latency_operations']) > 3:
        bottlenecks.append({
            "type": "high_latency",
            "severity": "low",
            "count": len(stats['high_latency_operations']),
            "avg_duration": sum(op['duration'] for op in stats['high_latency_operations']) / len(stats['high_latency_operations'])
        })
    
    # é¢‘ç¹æ“ä½œ
    for operation, count in stats['frequent_operations'].items():
        if count > FREQUENT_OPERATION_THRESHOLD:
            bottlenecks.append({
                "type": "frequent_operation",
                "severity": "low",
                "operation": operation,
                "count": count
            })
    
    # å¿ƒè·³è¿‡äºé¢‘ç¹
    if stats['heartbeat_count'] > 20:
        bottlenecks.append({
            "type": "excessive_heartbeats",
            "severity": "low",
            "count": stats['heartbeat_count']
        })
    
    # ç¼“å­˜å‘½ä¸­ç‡ä½
    if stats['cache_miss_rate'] > 0.5 and (stats['cache_hits'] + stats['cache_misses']) > 10:
        bottlenecks.append({
            "type": "low_cache_hit_rate",
            "severity": "medium",
            "miss_rate": stats['cache_miss_rate']
        })
    
    return bottlenecks


def suggest_optimizations(stats, bottlenecks):
    """æ ¹æ®ç“¶é¢ˆå»ºè®®ä¼˜åŒ–"""
    suggestions = []
    
    for opt_name, opt_config in OPTIMIZATIONS.items():
        if opt_config['condition'](stats):
            suggestions.append({
                "name": opt_name,
                "risk": opt_config['risk'],
                "description": opt_config['description'],
                "action": opt_config['action'],
                "params": opt_config['params']
            })
    
    return suggestions


def apply_optimization(optimization):
    """åº”ç”¨ä¼˜åŒ–ï¼ˆä»…ä½é£é™©ï¼‰"""
    if optimization['risk'] != 'low':
        return {
            "status": "skipped",
            "reason": f"risk level {optimization['risk']} requires manual approval"
        }
    
    action = optimization['action']
    params = optimization['params']
    
    # è¿™é‡Œæ˜¯å ä½ç¬¦ï¼Œå®é™…åº”ç”¨éœ€è¦æ ¹æ®å…·ä½“actionå®ç°
    # ç›®å‰åªè®°å½•åˆ°æ—¥å¿—ï¼Œä¸å®é™…ä¿®æ”¹é…ç½®
    
    result = {
        "status": "simulated",
        "action": action,
        "params": params,
        "timestamp": datetime.now().isoformat(),
        "note": "ä¼˜åŒ–å»ºè®®å·²è®°å½•ï¼Œç­‰å¾…å®é™…å®ç°"
    }
    
    # è®°å½•åˆ°ä¼˜åŒ–æ—¥å¿—
    OPTIMIZATION_LOG.parent.mkdir(exist_ok=True)
    with open(OPTIMIZATION_LOG, 'a', encoding='utf-8') as f:
        f.write(json.dumps(result, ensure_ascii=False) + '\n')
    
    return result


def main():
    """ä¸»å‡½æ•°"""
    print("âš¡ AIOS è‡ªåŠ¨æ€§èƒ½ä¼˜åŒ–")
    print("=" * 50)
    
    # 1. åŠ è½½æœ€è¿‘1å°æ—¶çš„äº‹ä»¶
    print("\nğŸ“Š åŠ è½½æ€§èƒ½æ•°æ®...")
    events = load_events(hours=1)
    print(f"   âœ… åŠ è½½ {len(events)} ä¸ªäº‹ä»¶")
    
    if len(events) < 10:
        print("   â„¹ï¸  æ•°æ®é‡ä¸è¶³ï¼Œè·³è¿‡åˆ†æ")
        print("\n" + "=" * 50)
        print("PERF_OK")
        return
    
    # 2. åˆ†ææ€§èƒ½
    print("\nğŸ” åˆ†ææ€§èƒ½æŒ‡æ ‡...")
    stats = analyze_performance(events)
    print(f"   ğŸ“ˆ æ…¢æ“ä½œ: {len(stats['slow_operations'])} ä¸ª")
    print(f"   ğŸ“ˆ é«˜å»¶è¿Ÿ: {len(stats['high_latency_operations'])} ä¸ª")
    print(f"   ğŸ“ˆ å¿ƒè·³æ¬¡æ•°: {stats['heartbeat_count']}")
    print(f"   ğŸ“ˆ ç¼“å­˜å‘½ä¸­ç‡: {(1 - stats['cache_miss_rate']) * 100:.1f}%")
    
    # 3. è¯†åˆ«ç“¶é¢ˆ
    print("\nğŸ¯ è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ...")
    bottlenecks = identify_bottlenecks(stats)
    
    if bottlenecks:
        print(f"   âš ï¸  å‘ç° {len(bottlenecks)} ä¸ªç“¶é¢ˆ")
        for bn in bottlenecks[:3]:
            print(f"   â€¢ {bn['type']} (ä¸¥é‡åº¦: {bn['severity']})")
    else:
        print("   âœ… æ— æ˜æ˜¾ç“¶é¢ˆ")
    
    # 4. å»ºè®®ä¼˜åŒ–
    print("\nğŸ’¡ ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
    suggestions = suggest_optimizations(stats, bottlenecks)
    
    if suggestions:
        print(f"   âœ… ç”Ÿæˆ {len(suggestions)} ä¸ªä¼˜åŒ–å»ºè®®")
        for sug in suggestions:
            print(f"   â€¢ {sug['description']} (é£é™©: {sug['risk']})")
    else:
        print("   âœ… ç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–")
    
    # 5. åº”ç”¨ä½é£é™©ä¼˜åŒ–
    applied = []
    if suggestions:
        print("\nğŸ”§ åº”ç”¨ä½é£é™©ä¼˜åŒ–...")
        for sug in suggestions:
            if sug['risk'] == 'low':
                result = apply_optimization(sug)
                if result['status'] in ['applied', 'simulated']:
                    applied.append(sug['name'])
                    print(f"   âœ… {sug['description']}")
    
    # 6. ä¿å­˜æ€§èƒ½æŠ¥å‘Š
    report = {
        "timestamp": datetime.now().isoformat(),
        "stats": {
            "total_events": stats['total_events'],
            "slow_operations_count": len(stats['slow_operations']),
            "high_latency_count": len(stats['high_latency_operations']),
            "heartbeat_count": stats['heartbeat_count'],
            "cache_miss_rate": stats['cache_miss_rate']
        },
        "bottlenecks": bottlenecks,
        "suggestions": suggestions,
        "applied": applied
    }
    
    with open(PERF_REPORT_FILE, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“Š æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {PERF_REPORT_FILE.relative_to(WORKSPACE)}")
    
    # 7. è¾“å‡ºå¿ƒè·³æ ¼å¼
    print("\n" + "=" * 50)
    if len(bottlenecks) > 0 and any(bn['severity'] == 'high' for bn in bottlenecks):
        print("PERF_DEGRADED")
    elif len(applied) > 0:
        print(f"PERF_OPTIMIZED:{len(applied)}")
    else:
        print("PERF_OK")


if __name__ == "__main__":
    main()
