#!/usr/bin/env python3
"""
AIOS è¶‹åŠ¿å¯¹æ¯” v1.0
ä¸‰ç»´åº¦å¯¹æ¯”ï¼šäº‹ä»¶é‡ / ç»“æ„å æ¯” / æˆåŠŸè´¨é‡
é˜ˆå€¼åˆ¤å®š + è¶…é™æ¨é€

ç”¨æ³•:
  python trend.py                  # å¯¹æ¯” 24h vs 7d æ—¥å‡
  python trend.py --save           # ä¿å­˜æŠ¥å‘Šåˆ° reports/
  python trend.py --format telegram  # Telegram æ ¼å¼
"""

import json, time, sys, argparse
from pathlib import Path
from datetime import datetime, timedelta

sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
from core.config import get_path

# â”€â”€ é˜ˆå€¼é…ç½® â”€â”€
THRESHOLDS = {
    "event_volume_pct": 30,  # äº‹ä»¶é‡åå·® > Â±30%
    "tool_ratio_spike_pct": 20,  # TOOL å æ¯”çªå¢ > 20%
    "tsr_min": 0.98,  # TSR < 98%
    "latency_spike_pct": 50,  # æ—¶å»¶ä¸Šå‡ > 50%
}

LAYERS = ["KERNEL", "COMMS", "TOOL", "MEM", "SEC"]


def load_events(since_hours=None):
    """åŠ è½½äº‹ä»¶ï¼Œå¯é€‰æ—¶é—´è¿‡æ»¤"""
    p = get_path("paths.events")
    if not p or not p.exists():
        return []
    events = []
    cutoff = time.time() - since_hours * 3600 if since_hours else 0
    for line in p.read_text(encoding="utf-8").strip().split("\n"):
        if not line.strip():
            continue
        try:
            e = json.loads(line)
            epoch = e.get("epoch", 0)
            if epoch >= cutoff:
                events.append(e)
        except json.JSONDecodeError:
            continue
    return events


def compute_metrics(events):
    """ä»äº‹ä»¶åˆ—è¡¨è®¡ç®—æŒ‡æ ‡"""
    total = len(events)
    layer_counts = {l: 0 for l in LAYERS}
    ok_count = 0
    latencies = []

    for e in events:
        layer = e.get("layer", "?")
        if layer in layer_counts:
            layer_counts[layer] += 1
        if e.get("status") == "ok":
            ok_count += 1
        ms = e.get("latency_ms")
        if ms is not None and ms > 0:
            latencies.append(ms)

    tsr = ok_count / total if total > 0 else 1.0
    retry_count = sum(1 for e in events if e.get("payload", {}).get("retry", False))
    retry_rate = retry_count / total if total > 0 else 0.0
    avg_latency = sum(latencies) / len(latencies) if latencies else 0
    p95_latency = sorted(latencies)[int(len(latencies) * 0.95)] if latencies else 0

    layer_ratios = {}
    for l in LAYERS:
        layer_ratios[l] = layer_counts[l] / total if total > 0 else 0

    return {
        "total": total,
        "tsr": tsr,
        "retry_rate": retry_rate,
        "avg_latency_ms": round(avg_latency, 1),
        "p95_latency_ms": round(p95_latency, 1),
        "layer_counts": layer_counts,
        "layer_ratios": {k: round(v, 3) for k, v in layer_ratios.items()},
    }


def compare(recent, baseline):
    """å¯¹æ¯”ä¸¤ç»„æŒ‡æ ‡ï¼Œè¿”å›å‘Šè­¦åˆ—è¡¨"""
    alerts = []

    # 1. äº‹ä»¶é‡åå·®
    if baseline["total"] > 0:
        vol_pct = ((recent["total"] - baseline["total"]) / baseline["total"]) * 100
        if abs(vol_pct) > THRESHOLDS["event_volume_pct"]:
            direction = "åé«˜" if vol_pct > 0 else "åä½"
            alerts.append(
                {
                    "dim": "äº‹ä»¶é‡",
                    "level": "WARN",
                    "msg": f"24h={recent['total']} vs æ—¥å‡={baseline['total']:.0f}ï¼Œ{direction} {abs(vol_pct):.0f}%",
                }
            )

    # 2. TOOL å æ¯”çªå¢
    tool_diff = (
        recent["layer_ratios"].get("TOOL", 0) - baseline["layer_ratios"].get("TOOL", 0)
    ) * 100
    if tool_diff > THRESHOLDS["tool_ratio_spike_pct"]:
        alerts.append(
            {
                "dim": "ç»“æ„å æ¯”",
                "level": "WARN",
                "msg": f"TOOL å æ¯” {recent['layer_ratios']['TOOL']*100:.0f}% â†’ çªå¢ {tool_diff:.0f}%",
            }
        )

    # 3. TSR
    if recent["tsr"] < THRESHOLDS["tsr_min"]:
        alerts.append(
            {
                "dim": "æˆåŠŸè´¨é‡",
                "level": "CRIT" if recent["tsr"] < 0.95 else "WARN",
                "msg": f"TSR={recent['tsr']*100:.1f}% (é˜ˆå€¼ {THRESHOLDS['tsr_min']*100:.0f}%)",
            }
        )

    # 4. æ—¶å»¶ä¸Šå‡
    if baseline["avg_latency_ms"] > 0:
        lat_pct = (
            (recent["avg_latency_ms"] - baseline["avg_latency_ms"])
            / baseline["avg_latency_ms"]
        ) * 100
        if lat_pct > THRESHOLDS["latency_spike_pct"]:
            alerts.append(
                {
                    "dim": "æˆåŠŸè´¨é‡",
                    "level": "WARN",
                    "msg": f"å¹³å‡æ—¶å»¶ {recent['avg_latency_ms']}ms â†’ ä¸Šå‡ {lat_pct:.0f}% (åŸºçº¿ {baseline['avg_latency_ms']}ms)",
                }
            )

    return alerts


def format_report(recent, baseline, alerts, fmt="markdown"):
    """ç”ŸæˆæŠ¥å‘Š"""
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    is_tg = fmt == "telegram"

    lines = []
    lines.append(f"{'ğŸ“Š' if is_tg else '##'} AIOS è¶‹åŠ¿å¯¹æ¯” | {now}")
    lines.append("")

    # ç»´åº¦1: äº‹ä»¶é‡
    lines.append(f"{'ğŸ“ˆ' if is_tg else '###'} äº‹ä»¶é‡")
    lines.append(f"  24h: {recent['total']} | 7dæ—¥å‡: {baseline['total']:.1f}")
    if baseline["total"] > 0:
        pct = ((recent["total"] - baseline["total"]) / baseline["total"]) * 100
        lines.append(f"  åå·®: {pct:+.0f}%")
    lines.append("")

    # ç»´åº¦2: ç»“æ„å æ¯”
    lines.append(f"{'ğŸ—ï¸' if is_tg else '###'} å±‚åˆ†å¸ƒ (24h vs 7dæ—¥å‡)")
    for l in LAYERS:
        r = recent["layer_ratios"].get(l, 0) * 100
        b = baseline["layer_ratios"].get(l, 0) * 100
        diff = r - b
        marker = " âš ï¸" if abs(diff) > 20 else ""
        lines.append(f"  {l}: {r:.0f}% vs {b:.0f}% ({diff:+.0f}%){marker}")
    lines.append("")

    # ç»´åº¦3: æˆåŠŸè´¨é‡
    lines.append(f"{'âœ…' if is_tg else '###'} æˆåŠŸè´¨é‡")
    lines.append(
        f"  TSR: {recent['tsr']*100:.1f}% | é‡è¯•ç‡: {recent['retry_rate']*100:.1f}%"
    )
    lines.append(
        f"  å¹³å‡æ—¶å»¶: {recent['avg_latency_ms']}ms | P95: {recent['p95_latency_ms']}ms"
    )
    lines.append("")

    # å‘Šè­¦
    if alerts:
        lines.append(f"{'ğŸš¨' if is_tg else '###'} è¶…é˜ˆå€¼å‘Šè­¦")
        for a in alerts:
            icon = "ğŸ”´" if a["level"] == "CRIT" else "ğŸŸ¡"
            lines.append(f"  {icon} [{a['dim']}] {a['msg']}")
    else:
        lines.append("ğŸŸ¢ å…¨éƒ¨æŒ‡æ ‡åœ¨é˜ˆå€¼å†…")

    return "\n".join(lines)


def run(args=None):
    parser = argparse.ArgumentParser(description="AIOS è¶‹åŠ¿å¯¹æ¯”")
    parser.add_argument("--save", action="store_true", help="ä¿å­˜æŠ¥å‘Š")
    parser.add_argument(
        "--format", choices=["markdown", "telegram"], default="markdown"
    )
    opts = parser.parse_args(args)

    # åŠ è½½æ•°æ®
    events_24h = load_events(since_hours=24)
    events_7d = load_events(since_hours=168)

    # è®¡ç®—æŒ‡æ ‡
    recent = compute_metrics(events_24h)

    # 7d æ—¥å‡åŸºçº¿
    if events_7d:
        baseline_raw = compute_metrics(events_7d)
        # è®¡ç®—å®é™…å¤©æ•°è·¨åº¦
        epochs = [e.get("epoch", 0) for e in events_7d if e.get("epoch")]
        if epochs:
            span_days = max((max(epochs) - min(epochs)) / 86400, 1)
        else:
            span_days = 7
        # æ—¥å‡åŒ–
        baseline = {
            "total": baseline_raw["total"] / span_days,
            "tsr": baseline_raw["tsr"],
            "retry_rate": baseline_raw["retry_rate"],
            "avg_latency_ms": baseline_raw["avg_latency_ms"],
            "p95_latency_ms": baseline_raw["p95_latency_ms"],
            "layer_counts": {
                k: v / span_days for k, v in baseline_raw["layer_counts"].items()
            },
            "layer_ratios": baseline_raw["layer_ratios"],
        }
    else:
        baseline = recent  # æ— å†å²æ•°æ®ï¼Œç”¨è‡ªèº«

    # å¯¹æ¯”
    alerts = compare(recent, baseline)

    # è¾“å‡º
    report = format_report(recent, baseline, alerts, fmt=opts.format)
    print(report)

    # ä¿å­˜
    if opts.save:
        reports_dir = Path(__file__).resolve().parent.parent / "reports"
        reports_dir.mkdir(parents=True, exist_ok=True)
        ts = datetime.now().strftime("%Y%m%d_%H%M")
        out = reports_dir / f"trend_{ts}.md"
        out.write_text(report, encoding="utf-8")
        print(f"\nğŸ’¾ å·²ä¿å­˜: {out}")

    # è¿”å›æ˜¯å¦æœ‰å‘Šè­¦ï¼ˆä¾›å¤–éƒ¨è°ƒç”¨ï¼‰
    return len(alerts) > 0, alerts


if __name__ == "__main__":
    run()
