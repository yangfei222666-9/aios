#!/usr/bin/env python3
"""
AIOS v0.5 æ€§èƒ½æ·±åº¦åˆ†æå·¥å…·
åˆ†ææ‰€æœ‰äº‹ä»¶æ—¥å¿—ï¼Œç”Ÿæˆå®Œæ•´çš„æ€§èƒ½æŠ¥å‘Š
"""

import json
import os
from collections import defaultdict, Counter
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import statistics

class PerformanceAnalyzer:
    def __init__(self, workspace_path: str):
        self.workspace = Path(workspace_path)
        self.events = []
        self.reactor_logs = []
        self.execution_logs = []
        
        # ç»Ÿè®¡æ•°æ®
        self.stats = {
            'total_events': 0,
            'by_layer': defaultdict(int),
            'by_event_type': defaultdict(int),
            'by_status': defaultdict(int),
            'latency_by_event': defaultdict(list),
            'errors': [],
            'cpu_spikes': [],
            'reactor_performance': {
                'total': 0,
                'success': 0,
                'failed': 0,
                'by_playbook': defaultdict(lambda: {'success': 0, 'failed': 0})
            },
            'execution_states': defaultdict(int),
            'action_performance': {
                'enqueued': 0,
                'succeeded': 0,
                'failed': 0,
                'skipped': 0,
                'by_type': defaultdict(lambda: {'success': 0, 'failed': 0})
            }
        }
    
    def load_jsonl(self, filepath: Path) -> List[Dict]:
        """åŠ è½½ JSONL æ–‡ä»¶"""
        data = []
        if not filepath.exists():
            return data
        
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        data.append(json.loads(line))
                    except json.JSONDecodeError as e:
                        print(f"JSON è§£æé”™è¯¯ {filepath}: {e}")
        return data
    
    def load_all_events(self):
        """åŠ è½½æ‰€æœ‰äº‹ä»¶æ–‡ä»¶"""
        event_files = [
            self.workspace / 'events.jsonl',
            self.workspace / 'events' / 'events.jsonl',
            self.workspace / 'data' / 'events.jsonl',
        ]
        
        for filepath in event_files:
            events = self.load_jsonl(filepath)
            self.events.extend(events)
            print(f"åŠ è½½ {filepath.name}: {len(events)} æ¡äº‹ä»¶")
        
        # åŠ è½½ reactor æ—¥å¿—
        reactor_file = self.workspace / 'reactor_log.jsonl'
        self.reactor_logs = self.load_jsonl(reactor_file)
        print(f"åŠ è½½ reactor_log.jsonl: {len(self.reactor_logs)} æ¡è®°å½•")
        
        # åŠ è½½æ‰§è¡Œæ—¥å¿—
        exec_file = self.workspace / 'events' / 'execution_log.jsonl'
        self.execution_logs = self.load_jsonl(exec_file)
        print(f"åŠ è½½ execution_log.jsonl: {len(self.execution_logs)} æ¡è®°å½•")
    
    def analyze_events(self):
        """åˆ†æäº‹ä»¶æ•°æ®"""
        self.stats['total_events'] = len(self.events)
        
        for event in self.events:
            # æŒ‰å±‚ç»Ÿè®¡
            layer = event.get('layer', 'UNKNOWN')
            self.stats['by_layer'][layer] += 1
            
            # æŒ‰äº‹ä»¶ç±»å‹ç»Ÿè®¡
            event_type = event.get('event') or event.get('type', 'unknown')
            self.stats['by_event_type'][event_type] += 1
            
            # æŒ‰çŠ¶æ€ç»Ÿè®¡
            status = event.get('status', 'unknown')
            self.stats['by_status'][status] += 1
            
            # å»¶è¿Ÿç»Ÿè®¡
            latency = event.get('latency_ms')
            if latency is not None:
                self.stats['latency_by_event'][event_type].append(latency)
            
            # é”™è¯¯æ”¶é›†
            if status in ['err', 'error']:
                self.stats['errors'].append({
                    'timestamp': event.get('ts') or event.get('timestamp'),
                    'layer': layer,
                    'event': event_type,
                    'payload': event.get('payload', {})
                })
            
            # CPU å³°å€¼
            if event_type in ['cpu_high', 'resource.cpu_spike']:
                cpu_percent = event.get('payload', {}).get('cpu_percent')
                self.stats['cpu_spikes'].append({
                    'timestamp': event.get('ts') or event.get('timestamp'),
                    'cpu_percent': cpu_percent
                })
            
            # Action æ€§èƒ½
            if 'action_enqueued' in event_type:
                self.stats['action_performance']['enqueued'] += 1
            elif 'action_succeeded' in event_type:
                self.stats['action_performance']['succeeded'] += 1
                action_type = event.get('payload', {}).get('type', 'unknown')
                self.stats['action_performance']['by_type'][action_type]['success'] += 1
            elif 'action_failed' in event_type:
                self.stats['action_performance']['failed'] += 1
                action_type = event.get('payload', {}).get('type', 'unknown')
                self.stats['action_performance']['by_type'][action_type]['failed'] += 1
            elif 'action_skipped' in event_type:
                self.stats['action_performance']['skipped'] += 1
    
    def analyze_reactor(self):
        """åˆ†æ Reactor æ€§èƒ½"""
        for log in self.reactor_logs:
            self.stats['reactor_performance']['total'] += 1
            
            status = log.get('status')
            playbook_id = log.get('playbook_id', 'unknown')
            
            if status == 'success':
                self.stats['reactor_performance']['success'] += 1
                self.stats['reactor_performance']['by_playbook'][playbook_id]['success'] += 1
            elif status == 'failed':
                self.stats['reactor_performance']['failed'] += 1
                self.stats['reactor_performance']['by_playbook'][playbook_id]['failed'] += 1
    
    def analyze_execution(self):
        """åˆ†ææ‰§è¡Œæ—¥å¿—"""
        for log in self.execution_logs:
            state = log.get('terminal_state', 'UNKNOWN')
            self.stats['execution_states'][state] += 1
    
    def calculate_latency_stats(self, latencies: List[float]) -> Dict:
        """è®¡ç®—å»¶è¿Ÿç»Ÿè®¡"""
        if not latencies:
            return {}
        
        return {
            'count': len(latencies),
            'min': min(latencies),
            'max': max(latencies),
            'mean': statistics.mean(latencies),
            'median': statistics.median(latencies),
            'p95': sorted(latencies)[int(len(latencies) * 0.95)] if len(latencies) > 1 else latencies[0],
            'p99': sorted(latencies)[int(len(latencies) * 0.99)] if len(latencies) > 1 else latencies[0]
        }
    
    def generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # 1. é”™è¯¯ç‡åˆ†æ
        error_rate = self.stats['by_status']['err'] / max(self.stats['total_events'], 1) * 100
        if error_rate > 10:
            recommendations.append(f"ğŸ”´ é”™è¯¯ç‡è¿‡é«˜ ({error_rate:.1f}%)ï¼Œéœ€è¦åŠ å¼ºé”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶")
        elif error_rate > 5:
            recommendations.append(f"ğŸŸ¡ é”™è¯¯ç‡åé«˜ ({error_rate:.1f}%)ï¼Œå»ºè®®ä¼˜åŒ–é”™è¯¯æ¢å¤ç­–ç•¥")
        
        # 2. Reactor æˆåŠŸç‡
        if self.stats['reactor_performance']['total'] > 0:
            reactor_success_rate = self.stats['reactor_performance']['success'] / self.stats['reactor_performance']['total'] * 100
            if reactor_success_rate < 80:
                recommendations.append(f"ğŸ”´ Reactor æˆåŠŸç‡è¿‡ä½ ({reactor_success_rate:.1f}%)ï¼Œéœ€è¦ä¿®å¤å¤±è´¥çš„ Playbook")
            
            # è¯†åˆ«å¤±è´¥çš„ Playbook
            for playbook_id, stats in self.stats['reactor_performance']['by_playbook'].items():
                total = stats['success'] + stats['failed']
                if total > 0 and stats['failed'] / total > 0.5:
                    recommendations.append(f"ğŸ”´ Playbook '{playbook_id}' å¤±è´¥ç‡è¿‡é«˜ï¼Œéœ€è¦ä¿®å¤")
        
        # 3. CPU å³°å€¼åˆ†æ
        if len(self.stats['cpu_spikes']) > 5:
            avg_cpu = statistics.mean([s['cpu_percent'] for s in self.stats['cpu_spikes'] if s['cpu_percent']])
            recommendations.append(f"âš ï¸ æ£€æµ‹åˆ° {len(self.stats['cpu_spikes'])} æ¬¡ CPU å³°å€¼ï¼ˆå¹³å‡ {avg_cpu:.1f}%ï¼‰ï¼Œå»ºè®®ä¼˜åŒ–èµ„æºå¯†é›†å‹æ“ä½œ")
        
        # 4. å»¶è¿Ÿåˆ†æ
        slow_events = []
        for event_type, latencies in self.stats['latency_by_event'].items():
            stats = self.calculate_latency_stats(latencies)
            if stats.get('p95', 0) > 1000:  # P95 > 1s
                slow_events.append((event_type, stats['p95']))
        
        if slow_events:
            recommendations.append(f"ğŸŒ å‘ç° {len(slow_events)} ç§æ…¢äº‹ä»¶ï¼ˆP95 > 1sï¼‰ï¼Œéœ€è¦æ€§èƒ½ä¼˜åŒ–")
            for event, p95 in sorted(slow_events, key=lambda x: x[1], reverse=True)[:3]:
                recommendations.append(f"   - {event}: P95 = {p95:.0f}ms")
        
        # 5. Action æ‰§è¡Œæ•ˆç‡
        if self.stats['action_performance']['enqueued'] > 0:
            skip_rate = self.stats['action_performance']['skipped'] / self.stats['action_performance']['enqueued'] * 100
            fail_rate = self.stats['action_performance']['failed'] / self.stats['action_performance']['enqueued'] * 100
            
            if skip_rate > 30:
                recommendations.append(f"â­ï¸ Action è·³è¿‡ç‡è¿‡é«˜ ({skip_rate:.1f}%)ï¼Œå¯èƒ½å­˜åœ¨é‡å¤æ“ä½œæˆ–è¿‡åº¦ä¿æŠ¤")
            
            if fail_rate > 20:
                recommendations.append(f"âŒ Action å¤±è´¥ç‡è¿‡é«˜ ({fail_rate:.1f}%)ï¼Œéœ€è¦æ”¹è¿›æ‰§è¡Œé€»è¾‘")
        
        # 6. æ‰§è¡ŒçŠ¶æ€åˆ†æ
        total_exec = sum(self.stats['execution_states'].values())
        if total_exec > 0:
            noop_rate = (self.stats['execution_states']['NOOP_DEDUP'] + 
                        self.stats['execution_states']['NOOP_ALREADY_RUNNING']) / total_exec * 100
            if noop_rate > 40:
                recommendations.append(f"ğŸ”„ NOOP æ¯”ä¾‹è¿‡é«˜ ({noop_rate:.1f}%)ï¼Œå»ºè®®ä¼˜åŒ–å»é‡ç­–ç•¥")
        
        # 7. å†…å­˜å’Œä¸Šä¸‹æ–‡ç®¡ç†
        context_prunes = self.stats['by_event_type'].get('context_prune', 0)
        if context_prunes > 10:
            recommendations.append(f"ğŸ’¾ é¢‘ç¹çš„ä¸Šä¸‹æ–‡ä¿®å‰ª ({context_prunes} æ¬¡)ï¼Œè€ƒè™‘å¢åŠ ä¸Šä¸‹æ–‡çª—å£æˆ–ä¼˜åŒ–å†…å­˜ç®¡ç†")
        
        # 8. å·¥å…·è°ƒç”¨ä¼˜åŒ–
        tool_execs = self.stats['by_event_type'].get('tool_exec', 0)
        if tool_execs > 50:
            recommendations.append(f"ğŸ”§ å·¥å…·è°ƒç”¨é¢‘ç¹ ({tool_execs} æ¬¡)ï¼Œè€ƒè™‘æ‰¹é‡æ“ä½œæˆ–ç¼“å­˜ç»“æœ")
        
        # 9. ç½‘ç»œé”™è¯¯
        network_errors = len([e for e in self.stats['errors'] if 'network' in str(e.get('event', '')).lower()])
        if network_errors > 3:
            recommendations.append(f"ğŸŒ ç½‘ç»œé”™è¯¯é¢‘ç¹ ({network_errors} æ¬¡)ï¼Œå»ºè®®å¢å¼ºé‡è¯•æœºåˆ¶å’Œè¶…æ—¶é…ç½®")
        
        # 10. æ–­è·¯å™¨è§¦å‘
        circuit_breaker = self.stats['by_event_type'].get('circuit_breaker_tripped', 0)
        deadloop_breaker = self.stats['by_event_type'].get('deadloop_breaker_tripped', 0)
        if circuit_breaker + deadloop_breaker > 0:
            recommendations.append(f"ğŸš¨ æ–­è·¯å™¨è§¦å‘ {circuit_breaker + deadloop_breaker} æ¬¡ï¼Œç³»ç»Ÿå­˜åœ¨ç¨³å®šæ€§é—®é¢˜")
        
        # 11. Agent é”™è¯¯
        agent_errors = len([e for e in self.events if e.get('type') == 'agent.error'])
        if agent_errors > 0:
            recommendations.append(f"ğŸ¤– Agent æ‰§è¡Œå¤±è´¥ {agent_errors} æ¬¡ï¼Œéœ€è¦æ”¹è¿›ä»»åŠ¡å¤„ç†é€»è¾‘")
        
        # 12. é€šç”¨å»ºè®®
        if len(recommendations) == 0:
            recommendations.append("âœ… ç³»ç»Ÿæ•´ä½“è¿è¡Œè‰¯å¥½ï¼Œç»§ç»­ä¿æŒ")
        
        recommendations.append("ğŸ“Š å»ºè®®å®šæœŸç›‘æ§å…³é”®æŒ‡æ ‡ï¼šé”™è¯¯ç‡ã€P95å»¶è¿Ÿã€CPUä½¿ç”¨ç‡ã€ReactoræˆåŠŸç‡")
        recommendations.append("ğŸ” å»ºè®®å®æ–½åˆ†å¸ƒå¼è¿½è¸ªï¼Œæ›´å¥½åœ°ç†è§£è¯·æ±‚é“¾è·¯")
        recommendations.append("âš¡ è€ƒè™‘å®æ–½æ€§èƒ½é¢„ç®—ï¼Œä¸ºå…³é”®æ“ä½œè®¾ç½®å»¶è¿Ÿé˜ˆå€¼")
        
        return recommendations
    
    def generate_visualization_data(self) -> Dict:
        """ç”Ÿæˆå¯è§†åŒ–æ•°æ®ï¼ˆJSON æ ¼å¼ï¼‰"""
        viz_data = {
            'summary': {
                'total_events': self.stats['total_events'],
                'error_rate': self.stats['by_status']['err'] / max(self.stats['total_events'], 1) * 100,
                'reactor_success_rate': (self.stats['reactor_performance']['success'] / 
                                        max(self.stats['reactor_performance']['total'], 1) * 100),
                'cpu_spike_count': len(self.stats['cpu_spikes'])
            },
            'events_by_layer': dict(self.stats['by_layer']),
            'events_by_type': dict(sorted(self.stats['by_event_type'].items(), 
                                         key=lambda x: x[1], reverse=True)[:20]),
            'latency_stats': {
                event_type: self.calculate_latency_stats(latencies)
                for event_type, latencies in self.stats['latency_by_event'].items()
                if latencies
            },
            'cpu_spikes': self.stats['cpu_spikes'],
            'reactor_performance': {
                'total': self.stats['reactor_performance']['total'],
                'success': self.stats['reactor_performance']['success'],
                'failed': self.stats['reactor_performance']['failed'],
                'by_playbook': dict(self.stats['reactor_performance']['by_playbook'])
            },
            'action_performance': {
                'enqueued': self.stats['action_performance']['enqueued'],
                'succeeded': self.stats['action_performance']['succeeded'],
                'failed': self.stats['action_performance']['failed'],
                'skipped': self.stats['action_performance']['skipped'],
                'by_type': dict(self.stats['action_performance']['by_type'])
            },
            'execution_states': dict(self.stats['execution_states']),
            'top_errors': self.stats['errors'][:10]
        }
        return viz_data
    
    def generate_report(self, output_path: Path):
        """ç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
        recommendations = self.generate_recommendations()
        viz_data = self.generate_visualization_data()
        
        # ä¿å­˜å¯è§†åŒ–æ•°æ®
        viz_path = output_path.parent / 'performance_visualization.json'
        with open(viz_path, 'w', encoding='utf-8') as f:
            json.dump(viz_data, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆ Markdown æŠ¥å‘Š
        report = []
        report.append("# AIOS v0.5 æ€§èƒ½æ·±åº¦åˆ†ææŠ¥å‘Š\n")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        report.append("---\n")
        
        # 1. æ‰§è¡Œæ‘˜è¦
        report.append("## ğŸ“Š æ‰§è¡Œæ‘˜è¦\n")
        report.append(f"- **æ€»äº‹ä»¶æ•°**: {self.stats['total_events']:,}")
        report.append(f"- **é”™è¯¯ç‡**: {viz_data['summary']['error_rate']:.2f}%")
        report.append(f"- **Reactor æˆåŠŸç‡**: {viz_data['summary']['reactor_success_rate']:.2f}%")
        report.append(f"- **CPU å³°å€¼æ¬¡æ•°**: {viz_data['summary']['cpu_spike_count']}")
        report.append(f"- **åˆ†ææ—¶é—´èŒƒå›´**: {self._get_time_range()}\n")
        
        # 2. äº‹ä»¶åˆ†å¸ƒ
        report.append("## ğŸ“ˆ äº‹ä»¶åˆ†å¸ƒåˆ†æ\n")
        report.append("### æŒ‰å±‚çº§ç»Ÿè®¡\n")
        for layer, count in sorted(self.stats['by_layer'].items(), key=lambda x: x[1], reverse=True):
            percentage = count / self.stats['total_events'] * 100
            report.append(f"- **{layer}**: {count} ({percentage:.1f}%)")
        report.append("")
        
        report.append("### æŒ‰äº‹ä»¶ç±»å‹ç»Ÿè®¡ï¼ˆTop 15ï¼‰\n")
        for event_type, count in sorted(self.stats['by_event_type'].items(), 
                                       key=lambda x: x[1], reverse=True)[:15]:
            percentage = count / self.stats['total_events'] * 100
            report.append(f"- **{event_type}**: {count} ({percentage:.1f}%)")
        report.append("")
        
        # 3. æ€§èƒ½æŒ‡æ ‡
        report.append("## âš¡ æ€§èƒ½æŒ‡æ ‡\n")
        report.append("### å»¶è¿Ÿåˆ†å¸ƒï¼ˆTop 10 æ…¢äº‹ä»¶ï¼‰\n")
        
        latency_items = []
        for event_type, latencies in self.stats['latency_by_event'].items():
            stats = self.calculate_latency_stats(latencies)
            if stats:
                latency_items.append((event_type, stats))
        
        for event_type, stats in sorted(latency_items, key=lambda x: x[1]['p95'], reverse=True)[:10]:
            report.append(f"\n**{event_type}**")
            report.append(f"- è°ƒç”¨æ¬¡æ•°: {stats['count']}")
            report.append(f"- å¹³å‡å»¶è¿Ÿ: {stats['mean']:.1f}ms")
            report.append(f"- ä¸­ä½æ•°: {stats['median']:.1f}ms")
            report.append(f"- P95: {stats['p95']:.1f}ms")
            report.append(f"- P99: {stats['p99']:.1f}ms")
            report.append(f"- æœ€å¤§å€¼: {stats['max']:.1f}ms")
        report.append("")
        
        # 4. CPU å³°å€¼åˆ†æ
        if self.stats['cpu_spikes']:
            report.append("## ğŸ”¥ CPU å³°å€¼åˆ†æ\n")
            cpu_values = [s['cpu_percent'] for s in self.stats['cpu_spikes'] if s['cpu_percent']]
            if cpu_values:
                report.append(f"- **å³°å€¼æ¬¡æ•°**: {len(cpu_values)}")
                report.append(f"- **å¹³å‡ CPU**: {statistics.mean(cpu_values):.1f}%")
                report.append(f"- **æœ€é«˜ CPU**: {max(cpu_values):.1f}%")
                report.append(f"- **æœ€ä½ CPU**: {min(cpu_values):.1f}%\n")
        
        # 5. Reactor æ‰§è¡Œæ•ˆç‡
        report.append("## ğŸ¯ Reactor æ‰§è¡Œæ•ˆç‡\n")
        report.append(f"- **æ€»æ‰§è¡Œæ¬¡æ•°**: {self.stats['reactor_performance']['total']}")
        report.append(f"- **æˆåŠŸæ¬¡æ•°**: {self.stats['reactor_performance']['success']}")
        report.append(f"- **å¤±è´¥æ¬¡æ•°**: {self.stats['reactor_performance']['failed']}")
        if self.stats['reactor_performance']['total'] > 0:
            success_rate = self.stats['reactor_performance']['success'] / self.stats['reactor_performance']['total'] * 100
            report.append(f"- **æˆåŠŸç‡**: {success_rate:.2f}%\n")
        
        report.append("### Playbook æ€§èƒ½\n")
        for playbook_id, stats in self.stats['reactor_performance']['by_playbook'].items():
            total = stats['success'] + stats['failed']
            success_rate = stats['success'] / total * 100 if total > 0 else 0
            status_icon = "âœ…" if success_rate >= 80 else "âš ï¸" if success_rate >= 50 else "âŒ"
            report.append(f"{status_icon} **{playbook_id}**: {stats['success']}/{total} ({success_rate:.1f}%)")
        report.append("")
        
        # 6. Action æ‰§è¡Œåˆ†æ
        if self.stats['action_performance']['enqueued'] > 0:
            report.append("## ğŸ¬ Action æ‰§è¡Œåˆ†æ\n")
            report.append(f"- **å…¥é˜Ÿæ•°é‡**: {self.stats['action_performance']['enqueued']}")
            report.append(f"- **æˆåŠŸæ‰§è¡Œ**: {self.stats['action_performance']['succeeded']}")
            report.append(f"- **æ‰§è¡Œå¤±è´¥**: {self.stats['action_performance']['failed']}")
            report.append(f"- **è¢«è·³è¿‡**: {self.stats['action_performance']['skipped']}")
            
            success_rate = self.stats['action_performance']['succeeded'] / self.stats['action_performance']['enqueued'] * 100
            skip_rate = self.stats['action_performance']['skipped'] / self.stats['action_performance']['enqueued'] * 100
            fail_rate = self.stats['action_performance']['failed'] / self.stats['action_performance']['enqueued'] * 100
            
            report.append(f"- **æˆåŠŸç‡**: {success_rate:.1f}%")
            report.append(f"- **è·³è¿‡ç‡**: {skip_rate:.1f}%")
            report.append(f"- **å¤±è´¥ç‡**: {fail_rate:.1f}%\n")
            
            report.append("### æŒ‰ç±»å‹ç»Ÿè®¡\n")
            for action_type, stats in sorted(self.stats['action_performance']['by_type'].items(),
                                            key=lambda x: x[1]['success'] + x[1]['failed'], reverse=True):
                total = stats['success'] + stats['failed']
                if total > 0:
                    success_rate = stats['success'] / total * 100
                    report.append(f"- **{action_type}**: {stats['success']}/{total} ({success_rate:.1f}%)")
            report.append("")
        
        # 7. æ‰§è¡ŒçŠ¶æ€åˆ†æ
        if self.stats['execution_states']:
            report.append("## ğŸ”„ æ‰§è¡ŒçŠ¶æ€åˆ†æ\n")
            total_exec = sum(self.stats['execution_states'].values())
            for state, count in sorted(self.stats['execution_states'].items(), 
                                      key=lambda x: x[1], reverse=True):
                percentage = count / total_exec * 100
                report.append(f"- **{state}**: {count} ({percentage:.1f}%)")
            report.append("")
        
        # 8. é”™è¯¯åˆ†æ
        if self.stats['errors']:
            report.append("## âŒ é”™è¯¯åˆ†æ\n")
            report.append(f"- **æ€»é”™è¯¯æ•°**: {len(self.stats['errors'])}")
            report.append(f"- **é”™è¯¯ç‡**: {len(self.stats['errors']) / self.stats['total_events'] * 100:.2f}%\n")
            
            # é”™è¯¯ç±»å‹ç»Ÿè®¡
            error_types = Counter([e['event'] for e in self.stats['errors']])
            report.append("### é”™è¯¯ç±»å‹åˆ†å¸ƒ\n")
            for error_type, count in error_types.most_common(10):
                report.append(f"- **{error_type}**: {count}")
            report.append("")
            
            # æœ€è¿‘çš„é”™è¯¯
            report.append("### æœ€è¿‘çš„é”™è¯¯ï¼ˆTop 5ï¼‰\n")
            for error in self.stats['errors'][-5:]:
                report.append(f"\n**{error['event']}** @ {error['timestamp']}")
                report.append(f"- Layer: {error['layer']}")
                payload = error.get('payload', {})
                if 'error' in payload:
                    report.append(f"- Error: {payload['error']}")
                if 'detail' in payload:
                    report.append(f"- Detail: {payload['detail']}")
            report.append("")
        
        # 9. ä¼˜åŒ–å»ºè®®
        report.append("## ğŸ’¡ ä¼˜åŒ–å»ºè®®\n")
        for i, rec in enumerate(recommendations, 1):
            report.append(f"{i}. {rec}")
        report.append("")
        
        # 10. é™„å½•
        report.append("## ğŸ“ é™„å½•\n")
        report.append(f"- **å¯è§†åŒ–æ•°æ®**: `{viz_path.name}`")
        report.append(f"- **åˆ†æè„šæœ¬**: `scripts/performance_analyzer.py`")
        report.append(f"- **æ•°æ®æº**: events.jsonl, reactor_log.jsonl, execution_log.jsonl")
        report.append("\n---")
        report.append("*æœ¬æŠ¥å‘Šç”± AIOS æ€§èƒ½åˆ†æå·¥å…·è‡ªåŠ¨ç”Ÿæˆ*")
        
        # å†™å…¥æŠ¥å‘Š
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))
        
        print(f"\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        print(f"âœ… å¯è§†åŒ–æ•°æ®å·²ä¿å­˜: {viz_path}")
    
    def _get_time_range(self) -> str:
        """è·å–æ—¶é—´èŒƒå›´"""
        timestamps = []
        for event in self.events:
            ts = event.get('ts') or event.get('timestamp') or event.get('epoch')
            if ts:
                timestamps.append(ts)
        
        if not timestamps:
            return "N/A"
        
        # å°è¯•è§£ææ—¶é—´æˆ³
        try:
            if isinstance(timestamps[0], str):
                # ISO æ ¼å¼
                times = [datetime.fromisoformat(ts.replace('Z', '+00:00')) for ts in timestamps if isinstance(ts, str)]
            else:
                # Unix æ—¶é—´æˆ³
                times = [datetime.fromtimestamp(ts) for ts in timestamps if isinstance(ts, (int, float))]
            
            if times:
                return f"{min(times).strftime('%Y-%m-%d %H:%M')} ~ {max(times).strftime('%Y-%m-%d %H:%M')}"
        except:
            pass
        
        return f"{len(timestamps)} events"
    
    def run(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("=" * 60)
        print("AIOS v0.5 æ€§èƒ½æ·±åº¦åˆ†æ")
        print("=" * 60)
        
        print("\n[1/5] åŠ è½½äº‹ä»¶æ•°æ®...")
        self.load_all_events()
        
        print("\n[2/5] åˆ†æäº‹ä»¶...")
        self.analyze_events()
        
        print("\n[3/5] åˆ†æ Reactor æ€§èƒ½...")
        self.analyze_reactor()
        
        print("\n[4/5] åˆ†ææ‰§è¡Œæ—¥å¿—...")
        self.analyze_execution()
        
        print("\n[5/5] ç”ŸæˆæŠ¥å‘Š...")
        output_path = self.workspace / 'reports' / 'performance_deep_analysis.md'
        output_path.parent.mkdir(parents=True, exist_ok=True)
        self.generate_report(output_path)
        
        print("\n" + "=" * 60)
        print("åˆ†æå®Œæˆï¼")
        print("=" * 60)


if __name__ == '__main__':
    workspace = Path(__file__).parent.parent
    analyzer = PerformanceAnalyzer(workspace)
    analyzer.run()
