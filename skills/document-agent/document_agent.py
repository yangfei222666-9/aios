#!/usr/bin/env python3
"""
Document Agent - æ–‡æ¡£å¤„ç† Agent
æ”¯æŒ docx/pdf/txt æ–‡æ¡£çš„æå–ã€æ‘˜è¦ã€ç»“æ„åŒ–è¾“å‡º
"""
import os
import json
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime


def extract_text_from_txt(file_path: Path) -> str:
    """ä» txt æ–‡ä»¶æå–æ–‡æœ¬"""
    try:
        # å°è¯•å¤šç§ç¼–ç 
        for encoding in ['utf-8', 'gbk', 'gb2312', 'latin-1']:
            try:
                return file_path.read_text(encoding=encoding)
            except UnicodeDecodeError:
                continue
        return ""
    except Exception as e:
        print(f"âš ï¸  è¯»å– txt å¤±è´¥: {e}")
        return ""


def extract_text_from_docx(file_path: Path) -> str:
    """ä» docx æ–‡ä»¶æå–æ–‡æœ¬"""
    try:
        import docx
        doc = docx.Document(file_path)
        return "\n".join([para.text for para in doc.paragraphs])
    except ImportError:
        print("âš ï¸  éœ€è¦å®‰è£… python-docx: pip install python-docx")
        return ""
    except Exception as e:
        print(f"âš ï¸  è¯»å– docx å¤±è´¥: {e}")
        return ""


def extract_text_from_pdf(file_path: Path) -> str:
    """ä» pdf æ–‡ä»¶æå–æ–‡æœ¬"""
    try:
        import pdfplumber
        text = []
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                text.append(page.extract_text() or "")
        return "\n".join(text)
    except ImportError:
        print("âš ï¸  éœ€è¦å®‰è£… pdfplumber: pip install pdfplumber")
        return ""
    except Exception as e:
        print(f"âš ï¸  è¯»å– pdf å¤±è´¥: {e}")
        return ""


def extract_text(file_path: Path) -> str:
    """æ ¹æ®æ–‡ä»¶ç±»å‹æå–æ–‡æœ¬"""
    suffix = file_path.suffix.lower()
    
    if suffix == '.txt':
        return extract_text_from_txt(file_path)
    elif suffix == '.docx':
        return extract_text_from_docx(file_path)
    elif suffix == '.pdf':
        return extract_text_from_pdf(file_path)
    else:
        print(f"âš ï¸  ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {suffix}")
        return ""


def generate_summary(text: str, max_length: int = 500) -> str:
    """ç”Ÿæˆæ‘˜è¦ï¼ˆç®€å•ç‰ˆæœ¬ï¼šæå–å‰Nä¸ªå­—ç¬¦ï¼‰"""
    # TODO: é›†æˆ LLM ç”Ÿæˆæ™ºèƒ½æ‘˜è¦
    if len(text) <= max_length:
        return text
    
    # ç®€å•æˆªæ–­åˆ°å¥å­è¾¹ç•Œ
    truncated = text[:max_length]
    last_period = max(truncated.rfind('ã€‚'), truncated.rfind('.'), truncated.rfind('ï¼'), truncated.rfind('!'))
    
    if last_period > 0:
        return truncated[:last_period + 1] + "..."
    else:
        return truncated + "..."


def extract_outline(text: str) -> List[str]:
    """æå–å¤§çº²ï¼ˆç®€å•ç‰ˆæœ¬ï¼šæå–æ ‡é¢˜è¡Œï¼‰"""
    lines = text.split('\n')
    outline = []
    
    for line in lines:
        line = line.strip()
        # æ£€æµ‹æ ‡é¢˜ï¼ˆç®€å•è§„åˆ™ï¼‰
        if line and (
            line.startswith('#') or  # Markdown æ ‡é¢˜
            line.isupper() or  # å…¨å¤§å†™
            (len(line) < 50 and not line.endswith(('ã€‚', '.', 'ï¼Œ', ',')))  # çŸ­è¡Œä¸”ä¸ä»¥æ ‡ç‚¹ç»“å°¾
        ):
            outline.append(line.lstrip('#').strip())
    
    return outline[:20]  # æœ€å¤š20ä¸ªæ ‡é¢˜


def extract_keywords(text: str, top_k: int = 10) -> List[str]:
    """æå–å…³é”®è¯ï¼ˆç®€å•ç‰ˆæœ¬ï¼šè¯é¢‘ç»Ÿè®¡ï¼‰"""
    # TODO: ä½¿ç”¨ TF-IDF æˆ– LLM æå–
    import re
    from collections import Counter
    
    # ç§»é™¤æ ‡ç‚¹å’Œæ•°å­—
    words = re.findall(r'[a-zA-Z\u4e00-\u9fa5]{2,}', text)
    
    # è¿‡æ»¤åœç”¨è¯ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰
    stopwords = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}
    words = [w for w in words if w not in stopwords and len(w) > 1]
    
    # ç»Ÿè®¡è¯é¢‘
    counter = Counter(words)
    return [word for word, count in counter.most_common(top_k)]


def process_document(file_path: Path, output_format: str = "json") -> Dict:
    """å¤„ç†æ–‡æ¡£"""
    print(f"ğŸ“„ å¤„ç†æ–‡æ¡£: {file_path.name}")
    
    # 1. æå–æ–‡æœ¬
    print("   æå–æ–‡æœ¬...")
    text = extract_text(file_path)
    
    if not text:
        return {
            "error": "æ— æ³•æå–æ–‡æœ¬",
            "file": str(file_path)
        }
    
    # 2. ç”Ÿæˆæ‘˜è¦
    print("   ç”Ÿæˆæ‘˜è¦...")
    summary = generate_summary(text, max_length=500)
    
    # 3. æå–å¤§çº²
    print("   æå–å¤§çº²...")
    outline = extract_outline(text)
    
    # 4. æå–å…³é”®è¯
    print("   æå–å…³é”®è¯...")
    keywords = extract_keywords(text, top_k=10)
    
    # 5. ç»Ÿè®¡ä¿¡æ¯
    word_count = len(text)
    line_count = len(text.split('\n'))
    
    result = {
        "file": str(file_path),
        "filename": file_path.name,
        "type": file_path.suffix,
        "processed_at": datetime.now().isoformat(),
        "stats": {
            "characters": word_count,
            "lines": line_count
        },
        "summary": summary,
        "outline": outline,
        "keywords": keywords
    }
    
    print(f"âœ… å®Œæˆï¼")
    print(f"   å­—ç¬¦æ•°: {word_count}")
    print(f"   å¤§çº²: {len(outline)} ä¸ªæ ‡é¢˜")
    print(f"   å…³é”®è¯: {', '.join(keywords[:5])}")
    
    return result


def save_result(result: Dict, output_path: Path, format: str = "json"):
    """ä¿å­˜ç»“æœ"""
    if format == "json":
        output_path.write_text(json.dumps(result, indent=2, ensure_ascii=False), encoding="utf-8")
    elif format == "markdown":
        md = f"""# {result['filename']}

## æ‘˜è¦

{result['summary']}

## å¤§çº²

{chr(10).join(f"- {item}" for item in result['outline'])}

## å…³é”®è¯

{', '.join(result['keywords'])}

## ç»Ÿè®¡

- å­—ç¬¦æ•°: {result['stats']['characters']}
- è¡Œæ•°: {result['stats']['lines']}
- å¤„ç†æ—¶é—´: {result['processed_at']}
"""
        output_path.write_text(md, encoding="utf-8")


def main():
    import sys
    
    if len(sys.argv) < 2:
        print("""
ğŸ“„ Document Agent - æ–‡æ¡£å¤„ç†å·¥å…·

ç”¨æ³•:
  python document_agent.py <æ–‡ä»¶è·¯å¾„> [è¾“å‡ºæ ¼å¼]

è¾“å‡ºæ ¼å¼:
  json (é»˜è®¤) - JSON æ ¼å¼
  markdown    - Markdown æ ¼å¼

ç¤ºä¾‹:
  python document_agent.py report.docx
  python document_agent.py report.pdf markdown
        """)
        return
    
    file_path = Path(sys.argv[1])
    output_format = sys.argv[2] if len(sys.argv) > 2 else "json"
    
    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    # å¤„ç†æ–‡æ¡£
    result = process_document(file_path, output_format)
    
    if "error" in result:
        print(f"âŒ {result['error']}")
        return
    
    # ä¿å­˜ç»“æœ
    output_ext = ".json" if output_format == "json" else ".md"
    output_path = file_path.with_suffix(output_ext)
    save_result(result, output_path, output_format)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {output_path}")


if __name__ == "__main__":
    main()
