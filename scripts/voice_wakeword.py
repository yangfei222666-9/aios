# scripts/voice_wakeword.py - è¯­éŸ³å”¤é†’ + Push-to-Talk
"""
æŒç»­ç›‘å¬éº¦å…‹é£ï¼Œæ£€æµ‹åˆ°"å°ä¹"åå¼€å§‹å½•éŸ³ï¼Œ
é™éŸ³åè‡ªåŠ¨åœæ­¢å¹¶è½¬å†™å‘é€ã€‚

ä¹Ÿæ”¯æŒ F2 æŒ‰ä½è¯´è¯ï¼ˆå…¼å®¹ PTT æ¨¡å¼ï¼‰ã€‚

ç”¨æ³•ï¼š
  pythonw voice_wakeword.py        # æ— çª—å£åå°è¿è¡Œ
  python -u voice_wakeword.py      # æœ‰çª—å£è°ƒè¯•
"""
import sys, os, io, time, json, tempfile, threading, argparse, collections
os.environ['PYTHONUNBUFFERED'] = '1'

LOG_PATH = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "logs", "voice_wakeword.log")
if sys.stdout is None or not hasattr(sys.stdout, 'buffer'):
    os.makedirs(os.path.dirname(LOG_PATH), exist_ok=True)
    log_file = open(LOG_PATH, "a", encoding="utf-8")
    sys.stdout = log_file
    sys.stderr = log_file
else:
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace', line_buffering=True)

import numpy as np
import sounddevice as sd
import soundfile as sf
from pynput import keyboard as kb

# ---- Config ----
SAMPLE_RATE = 16000
CHANNELS = 1
WHISPER_MODEL = "large-v3"
WHISPER_DEVICE = "cuda"
WHISPER_COMPUTE = "int8_float16"

BOT_TOKEN = "8278846913:AAGX6omR8aXEOWgcMBX3Y0EsJUGI2b2BE0s"
CHAT_ID = "7986452220"

WAKE_WORD = "å°ä¹"
WAKE_WINDOW_SEC = 1.2       # å”¤é†’æ£€æµ‹çª—å£
WAKE_CHECK_INTERVAL = 0.6   # æ¯0.6ç§’æ£€æµ‹ä¸€æ¬¡
SILENCE_TIMEOUT = 3.0       # é™éŸ³3ç§’å†åœæ­¢ï¼Œç»™æ€è€ƒæ—¶é—´
SILENCE_THRESHOLD = 0.008   # é™éŸ³ RMS é˜ˆå€¼
MIN_RECORD_SEC = 0.5        # æœ€çŸ­å½•éŸ³æ—¶é•¿

# ---- State ----
class State:
    model = None
    recording = False       # PTT å½•éŸ³ä¸­
    wake_listening = False  # å”¤é†’åå½•éŸ³ä¸­
    audio_frames = []
    wake_buffer = collections.deque(maxlen=int(SAMPLE_RATE * WAKE_WINDOW_SEC))
    last_wake_check = 0
    lock = threading.Lock()

S = State()

def load_model():
    if S.model is None:
        print(f"[{ts()}] â³ åŠ è½½ Whisper æ¨¡å‹...")
        t0 = time.time()
        from faster_whisper import WhisperModel
        S.model = WhisperModel(WHISPER_MODEL, device=WHISPER_DEVICE, compute_type=WHISPER_COMPUTE)
        print(f"[{ts()}] âœ… æ¨¡å‹å°±ç»ª ({time.time()-t0:.1f}s)")
    return S.model

def ts():
    return time.strftime("%H:%M:%S")

def audio_callback(indata, frames, time_info, status):
    flat = indata[:, 0]
    
    # å§‹ç»ˆå¡«å……å”¤é†’ç¼“å†²åŒº
    S.wake_buffer.extend(flat)
    
    # PTT æˆ–å”¤é†’å½•éŸ³ä¸­
    if S.recording or S.wake_listening:
        S.audio_frames.append(flat.copy())

def transcribe_audio(audio_data):
    """è½¬å†™éŸ³é¢‘ï¼Œè¿”å›æ–‡æœ¬"""
    if len(audio_data) < SAMPLE_RATE * 0.3:
        return ""
    
    tmp_path = os.path.join(tempfile.gettempdir(), "wakeword_rec.wav")
    sf.write(tmp_path, audio_data, SAMPLE_RATE)
    
    m = load_model()
    segments, info = m.transcribe(
        tmp_path, language="zh", beam_size=1,
        no_speech_threshold=0.5, vad_filter=True,
        vad_parameters=dict(min_silence_duration_ms=300),
    )
    text = "".join(seg.text for seg in segments).strip()
    
    try:
        os.remove(tmp_path)
    except:
        pass
    
    return text

def send_to_telegram(text):
    import urllib.request
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = json.dumps({"chat_id": CHAT_ID, "text": f"ğŸ™ï¸ {text}"}).encode("utf-8")
    try:
        req = urllib.request.Request(url, data=payload, method="POST")
        req.add_header("Content-Type", "application/json")
        with urllib.request.urlopen(req, timeout=5) as resp:
            if resp.status == 200:
                print(f"[{ts()}] âœ… å·²å‘é€: {text}")
                return True
    except Exception as e:
        print(f"[{ts()}] âš ï¸ å‘é€å¤±è´¥: {e}")
    return False

# ---- å”¤é†’æ£€æµ‹ ----
def check_wake_word():
    """æ£€æŸ¥å”¤é†’ç¼“å†²åŒºæ˜¯å¦åŒ…å«å”¤é†’è¯"""
    now = time.time()
    if now - S.last_wake_check < WAKE_CHECK_INTERVAL:
        return False
    if S.recording or S.wake_listening:
        return False
    
    S.last_wake_check = now
    
    buf = np.array(list(S.wake_buffer), dtype=np.float32)
    if len(buf) < SAMPLE_RATE * 0.5:
        return False
    
    rms = np.sqrt(np.mean(buf ** 2))
    if rms < 0.003:  # é™ä½é˜ˆå€¼ï¼Œæ›´çµæ•
        return False
    
    text = transcribe_audio(buf)
    if WAKE_WORD in text:
        print(f"[{ts()}] ğŸ”” å”¤é†’è¯æ£€æµ‹åˆ°: \"{text}\"")
        return True
    return False

def wake_record_loop():
    """å”¤é†’åå¼€å§‹å½•éŸ³ï¼Œé™éŸ³è‡ªåŠ¨åœæ­¢"""
    S.wake_listening = True
    S.audio_frames = []
    
    # æ’­æ”¾æç¤ºéŸ³
    try:
        import winsound
        winsound.Beep(800, 150)  # 800Hz, 150ms
    except:
        pass
    
    print(f"[{ts()}] ğŸ™ï¸ å”¤é†’å½•éŸ³å¼€å§‹ï¼Œè¯´è¯å§...")
    
    last_sound_time = time.time()
    
    while S.wake_listening:
        time.sleep(0.1)
        
        if S.audio_frames:
            recent = S.audio_frames[-1] if S.audio_frames else np.zeros(1)
            rms = np.sqrt(np.mean(recent ** 2))
            
            if rms > SILENCE_THRESHOLD:
                last_sound_time = time.time()
            elif time.time() - last_sound_time > SILENCE_TIMEOUT:
                break
    
    S.wake_listening = False
    
    if not S.audio_frames:
        print(f"[{ts()}] âš ï¸ æ²¡æœ‰å½•åˆ°éŸ³é¢‘")
        return
    
    audio_data = np.concatenate(S.audio_frames)
    duration = len(audio_data) / SAMPLE_RATE
    
    if duration < MIN_RECORD_SEC:
        print(f"[{ts()}] âš ï¸ å½•éŸ³å¤ªçŸ­ ({duration:.1f}s)")
        return
    
    print(f"[{ts()}] â¹ï¸ å½•éŸ³ç»“æŸ ({duration:.1f}s)ï¼Œè½¬å†™ä¸­...")
    
    t0 = time.time()
    text = transcribe_audio(audio_data)
    elapsed = time.time() - t0
    
    # å»æ‰å”¤é†’è¯æœ¬èº«ï¼ˆåªå»ç¬¬ä¸€ä¸ªï¼‰
    if WAKE_WORD in text:
        idx = text.index(WAKE_WORD)
        text = text[idx + len(WAKE_WORD):]
    text = text.lstrip("ï¼Œã€‚,. !ï¼?ï¼Ÿ")
    
    if not text:
        print(f"[{ts()}] âš ï¸ æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹")
        return
    
    print(f"[{ts()}] ğŸ’¬ è¯†åˆ«ç»“æœ ({elapsed:.1f}s): {text}")
    send_to_telegram(text)

# ---- PTT (F2) ----
def ptt_start():
    if S.recording or S.wake_listening:
        return
    S.recording = True
    S.audio_frames = []
    print(f"[{ts()}] ğŸ™ï¸ PTT å½•éŸ³ä¸­... (æ¾å¼€åœæ­¢)")

def ptt_stop():
    if not S.recording:
        return
    S.recording = False
    
    if not S.audio_frames:
        return
    
    frames_copy = list(S.audio_frames)
    t = threading.Thread(target=_ptt_transcribe, args=(frames_copy,), daemon=True)
    t.start()

def _ptt_transcribe(frames):
    audio_data = np.concatenate(frames)
    rms = np.sqrt(np.mean(audio_data ** 2))
    if rms < 0.005:
        return
    
    duration = len(audio_data) / SAMPLE_RATE
    print(f"[{ts()}] ğŸ“ PTT éŸ³é¢‘ {duration:.1f}s")
    
    t0 = time.time()
    text = transcribe_audio(audio_data)
    elapsed = time.time() - t0
    
    if text:
        print(f"[{ts()}] ğŸ’¬ PTT ç»“æœ ({elapsed:.1f}s): {text}")
        send_to_telegram(text)

# ---- Main ----
def main():
    print(f"[{ts()}] ğŸ¾ å°ä¹è¯­éŸ³åŠ©æ‰‹")
    print(f"[{ts()}]    å”¤é†’è¯: \"{WAKE_WORD}\"")
    print(f"[{ts()}]    PTTå¿«æ·é”®: F2")
    print(f"[{ts()}]    æ¨¡å‹: {WHISPER_MODEL} ({WHISPER_COMPUTE})")
    print()
    
    load_model()
    
    # éŸ³é¢‘æµ
    stream = sd.InputStream(
        samplerate=SAMPLE_RATE, channels=CHANNELS,
        callback=audio_callback, dtype='float32',
        blocksize=int(SAMPLE_RATE * 0.1),  # 100ms å—
    )
    stream.start()
    
    # PTT å¿«æ·é”®
    def on_press(key):
        if key == kb.Key.f2:
            ptt_start()
    
    def on_release(key):
        if key == kb.Key.f2:
            ptt_stop()
    
    listener = kb.Listener(on_press=on_press, on_release=on_release)
    listener.start()
    
    print(f"[{ts()}] ğŸŸ¢ å°±ç»ªï¼Œè¯´\"{WAKE_WORD}\"å”¤é†’ æˆ–æŒ‰ F2 è¯´è¯\n")
    
    # ä¸»å¾ªç¯ï¼šå”¤é†’æ£€æµ‹
    try:
        while True:
            time.sleep(0.2)
            
            if not S.recording and not S.wake_listening:
                if check_wake_word():
                    # æ¸…ç©ºç¼“å†²åŒºï¼Œå¼€å§‹å½•éŸ³
                    S.wake_buffer.clear()
                    t = threading.Thread(target=wake_record_loop, daemon=True)
                    t.start()
    except KeyboardInterrupt:
        pass
    finally:
        stream.stop()
        stream.close()
        listener.stop()
        print(f"\n[{ts()}] ğŸ‘‹ å·²é€€å‡º")

if __name__ == "__main__":
    main()
