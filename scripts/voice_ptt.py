# scripts/voice_ptt.py - Push-to-Talk è¯­éŸ³è¾“å…¥
"""
æŒ‰ä½å¿«æ·é”®è¯´è¯ï¼Œæ¾å¼€è‡ªåŠ¨è½¬å†™å‘é€ç»™å°ä¹ã€‚

ç”¨æ³•ï¼š
  python voice_ptt.py          # é»˜è®¤å¿«æ·é”® f2
  python voice_ptt.py --key f5 # è‡ªå®šä¹‰å¿«æ·é”®
"""
import sys, os, io, time, json, tempfile, threading, argparse
os.environ['PYTHONUNBUFFERED'] = '1'
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace', line_buffering=True)

import numpy as np
import sounddevice as sd
import soundfile as sf
import keyboard

# ---- Config ----
SAMPLE_RATE = 16000
CHANNELS = 1
WHISPER_MODEL = "large-v3"
WHISPER_DEVICE = "cuda"
WHISPER_COMPUTE = "int8_float16"

# ---- Global state ----
recording = False
audio_frames = []
model = None

def load_model():
    global model
    if model is None:
        print("â³ åŠ è½½ Whisper æ¨¡å‹...")
        t0 = time.time()
        from faster_whisper import WhisperModel
        model = WhisperModel(WHISPER_MODEL, device=WHISPER_DEVICE, compute_type=WHISPER_COMPUTE)
        print(f"âœ… æ¨¡å‹å°±ç»ª ({time.time()-t0:.1f}s)")
    return model

def audio_callback(indata, frames, time_info, status):
    if recording:
        audio_frames.append(indata.copy())

def start_recording():
    global recording, audio_frames
    if recording:
        return
    audio_frames = []
    recording = True
    print("ğŸ™ï¸ å½•éŸ³ä¸­... (æ¾å¼€åœæ­¢)")

def stop_recording():
    global recording
    if not recording:
        return
    recording = False
    
    if not audio_frames:
        print("âš ï¸ æ²¡æœ‰å½•åˆ°éŸ³é¢‘")
        return
    
    print("â¹ï¸ å½•éŸ³ç»“æŸï¼Œè½¬å†™ä¸­...")
    # åå°çº¿ç¨‹è½¬å†™ï¼Œä¸é˜»å¡å¿«æ·é”®ç›‘å¬
    frames_copy = list(audio_frames)
    t = threading.Thread(target=_transcribe_and_send, args=(frames_copy,), daemon=True)
    t.start()

def _transcribe_and_send(frames):
    audio_data = np.concatenate(frames, axis=0)
    
    rms = np.sqrt(np.mean(audio_data ** 2))
    if rms < 0.005:
        print("âš ï¸ éŸ³é‡å¤ªä½ï¼Œè·³è¿‡")
        return
    
    tmp_path = os.path.join(tempfile.gettempdir(), "ptt_recording.wav")
    sf.write(tmp_path, audio_data, SAMPLE_RATE)
    
    duration = len(audio_data) / SAMPLE_RATE
    print(f"ğŸ“ éŸ³é¢‘ {duration:.1f}s, RMS={rms:.4f}")
    
    # åˆ†æ­¥è®¡æ—¶
    t0 = time.time()
    m = load_model()
    t_model = time.time() - t0
    
    t1 = time.time()
    segments, info = m.transcribe(
        tmp_path,
        language="zh",
        beam_size=1,
        no_speech_threshold=0.5,
        vad_filter=True,
        vad_parameters=dict(min_silence_duration_ms=300),
    )
    text = "".join(seg.text for seg in segments).strip()
    t_transcribe = time.time() - t1
    
    if not text:
        print("âš ï¸ æœªè¯†åˆ«åˆ°è¯­éŸ³")
        return
    
    total = t_model + t_transcribe
    print(f"ğŸ’¬ è¯†åˆ«ç»“æœ: {text}")
    print(f"â±ï¸ æ¨¡å‹={t_model:.1f}s è½¬å†™={t_transcribe:.1f}s æ€»è®¡={total:.1f}s")
    
    # å‘é€
    t2 = time.time()
    send_to_openclaw(text)
    t_send = time.time() - t2
    print(f"ğŸ“¤ å‘é€={t_send:.1f}s")
    
    try:
        os.remove(tmp_path)
    except:
        pass

def send_to_openclaw(text):
    """ç›´æ¥é€šè¿‡ Telegram Bot API å‘æ¶ˆæ¯ï¼Œæœ€å¿«çš„æ–¹å¼"""
    import urllib.request, urllib.error
    
    bot_token = "8278846913:AAGX6omR8aXEOWgcMBX3Y0EsJUGI2b2BE0s"
    chat_id = "7986452220"
    
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    payload = json.dumps({
        "chat_id": chat_id,
        "text": f"ğŸ™ï¸ {text}",
    }).encode("utf-8")
    
    try:
        req = urllib.request.Request(url, data=payload, method="POST")
        req.add_header("Content-Type", "application/json")
        with urllib.request.urlopen(req, timeout=5) as resp:
            if resp.status == 200:
                print(f"âœ… å·²å‘é€ç»™å°ä¹: {text}")
                return
    except Exception as e:
        print(f"âš ï¸ Telegram å‘é€å¤±è´¥: {e}")
    
    # å¤‡é€‰ï¼šå†™æ–‡ä»¶
    fallback_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        "memory", "voice_inbox.jsonl"
    )
    with open(fallback_path, "a", encoding="utf-8") as f:
        f.write(json.dumps({
            "ts": int(time.time()),
            "text": text,
            "source": "ptt",
            "delivered": False,
        }, ensure_ascii=False) + "\n")
    print(f"ğŸ“¥ å·²å­˜å…¥ voice_inbox.jsonl")

def main():
    parser = argparse.ArgumentParser(description="Push-to-Talk è¯­éŸ³è¾“å…¥")
    parser.add_argument("--key", default="f2", help="å¿«æ·é”® (é»˜è®¤ f2)")
    args = parser.parse_args()
    
    hotkey = args.key
    
    print(f"ğŸ¾ å°ä¹è¯­éŸ³è¾“å…¥ (Push-to-Talk)")
    print(f"   å¿«æ·é”®: {hotkey}")
    print(f"   æ¨¡å‹: {WHISPER_MODEL} ({WHISPER_COMPUTE})")
    print(f"   æŒ‰ä½è¯´è¯ï¼Œæ¾å¼€å‘é€")
    print(f"   Ctrl+C é€€å‡º")
    print()
    
    load_model()
    
    stream = sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=CHANNELS,
        callback=audio_callback,
        dtype='float32',
    )
    stream.start()
    
    last_key = hotkey.split('+')[-1]
    if '+' in hotkey:
        keyboard.add_hotkey(hotkey, start_recording, suppress=False)
    else:
        keyboard.on_press_key(last_key, lambda e: start_recording(), suppress=False)
    keyboard.on_release_key(last_key, lambda e: stop_recording(), suppress=False)
    
    print("ğŸŸ¢ å°±ç»ªï¼Œç­‰å¾…è¯­éŸ³è¾“å…¥...\n")
    
    try:
        keyboard.wait('ctrl+c')
    except KeyboardInterrupt:
        pass
    finally:
        stream.stop()
        stream.close()
        print("\nğŸ‘‹ å·²é€€å‡º")

if __name__ == "__main__":
    main()
