"""alerts.py - å¼‚å¸¸åˆ†çº§ä¸è‡ªåŠ¨é™å™ªç³»ç»Ÿ
ä¸‰çº§äº‹ä»¶: INFO(ä»…è½ç›˜) / WARN(è¿›å‘¨æŠ¥) / CRIT(ç«‹å³æ¨é€)
5æ¡è§„åˆ™: è¿ç»­å¤±è´¥ / æ•°æ®é‡éª¤é™ / å…³é”®æ–‡ä»¶ç¼ºå¤± / APIè¶…æ—¶ç‡ / å¤‡ä»½å¤±è´¥
å†·å´æœºåˆ¶: åŒç±»äº‹ä»¶6å°æ—¶å†…åªæŠ¥ä¸€æ¬¡
ç¼“å­˜æœºåˆ¶: ç»“æœç¼“å­˜5åˆ†é’Ÿï¼Œå‡å°‘é‡å¤æ‰§è¡Œå¼€é”€
"""
import json, os, time, subprocess, sys, io
from datetime import datetime, timedelta

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

# å¯¼å…¥é—­ç¯çŠ¶æ€æœº
sys.path.insert(0, os.path.dirname(__file__))
import alert_fsm

WS = r'C:\Users\A\.openclaw\workspace'

# å¯¼å…¥ AIOS dispatcherï¼ˆæ„ŸçŸ¥æ‰«æï¼‰
try:
    sys.path.insert(0, os.path.join(WS, 'aios'))
    from core.dispatcher import dispatch as aios_dispatch, get_pending_actions, clear_actions
    HAS_DISPATCHER = True
except ImportError:
    HAS_DISPATCHER = False
PYTHON = r'C:\Program Files\Python312\python.exe'
ALERTS_STATE = os.path.join(WS, 'memory', 'alerts_state.json')
ALERTS_LOG = os.path.join(WS, 'memory', 'alerts_log.jsonl')
ALERTS_CACHE = os.path.join(WS, 'memory', 'alerts_cache.json')
COOLDOWN_HOURS = 6
CACHE_TTL_SECONDS = 300  # 5åˆ†é’Ÿç¼“å­˜
DEDUP_WINDOW_SECONDS = 60  # åŒä¸€å‘½ä»¤60ç§’å†…å»é‡

# --- Cache Management ---

def load_cache():
    """åŠ è½½ç¼“å­˜ï¼Œå¦‚æœæœªè¿‡æœŸåˆ™è¿”å›ç»“æœ"""
    if not os.path.exists(ALERTS_CACHE):
        return None
    
    try:
        with open(ALERTS_CACHE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
        
        cached_at = cache.get('cached_at', 0)
        age = time.time() - cached_at
        
        if age < CACHE_TTL_SECONDS:
            return cache.get('data')
        else:
            return None
    except:
        return None

def save_cache(data):
    """ä¿å­˜ç»“æœåˆ°ç¼“å­˜"""
    cache = {
        'cached_at': time.time(),
        'data': data
    }
    with open(ALERTS_CACHE, 'w', encoding='utf-8') as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)

# --- State Management ---

def load_state():
    if os.path.exists(ALERTS_STATE):
        with open(ALERTS_STATE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {"last_alerts": {}, "counters": {}}

def save_state(state):
    with open(ALERTS_STATE, 'w', encoding='utf-8') as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def log_event(level, rule, message):
    entry = {
        "ts": datetime.now().isoformat(),
        "level": level,
        "rule": rule,
        "message": message
    }
    with open(ALERTS_LOG, 'a', encoding='utf-8') as f:
        f.write(json.dumps(entry, ensure_ascii=False) + '\n')
    return entry

def is_cooled_down(state, rule_id):
    last = state.get("last_alerts", {}).get(rule_id)
    if not last:
        return True
    last_ts = datetime.fromisoformat(last)
    return (datetime.now() - last_ts).total_seconds() > COOLDOWN_HOURS * 3600

def mark_alerted(state, rule_id):
    if "last_alerts" not in state:
        state["last_alerts"] = {}
    state["last_alerts"][rule_id] = datetime.now().isoformat()
    if "counters" not in state:
        state["counters"] = {}
    state["counters"][rule_id] = state["counters"].get(rule_id, 0) + 1

# --- Rule Checks ---

def check_consecutive_failures(state):
    """è§„åˆ™1: autolearn smoke è¿ç»­å¤±è´¥"""
    try:
        r = subprocess.run([PYTHON, '-m', 'autolearn', 'health'],
                          cwd=WS, capture_output=True, text=True, timeout=15)
        if 'FAIL' in r.stdout and '0 FAIL' not in r.stdout:
            return "CRIT", "autolearn smoke æµ‹è¯•æœ‰å¤±è´¥é¡¹"
        return "INFO", "autolearn smoke å…¨éƒ¨é€šè¿‡"
    except:
        return "WARN", "autolearn health æ‰§è¡Œè¶…æ—¶æˆ–å¼‚å¸¸"

def check_data_drop():
    """è§„åˆ™2: ARAM æ•°æ®é‡éª¤é™"""
    db_path = os.path.join(os.environ['USERPROFILE'], 'Desktop', 'ARAM-Helper', 'aram_data.json')
    try:
        with open(db_path, 'r', encoding='utf-8') as f:
            db = json.load(f)
        count = len(db)
        if count < 150:
            return "CRIT", f"ARAM æ•°æ®åº“åªæœ‰ {count} è‹±é›„ï¼ˆé¢„æœŸ 172ï¼‰ï¼Œæ•°æ®å¯èƒ½æŸå"
        elif count < 170:
            return "WARN", f"ARAM æ•°æ®åº“ {count} è‹±é›„ï¼Œä½äºé¢„æœŸ 172"
        return "INFO", f"ARAM æ•°æ®åº“ {count} è‹±é›„ï¼Œæ­£å¸¸"
    except FileNotFoundError:
        return "CRIT", "ARAM æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼"
    except:
        return "WARN", "ARAM æ•°æ®åº“è¯»å–å¼‚å¸¸"

def check_critical_files():
    """è§„åˆ™3: å…³é”®æ–‡ä»¶ç¼ºå¤±"""
    critical = [
        os.path.join(WS, 'MEMORY.md'),
        os.path.join(WS, 'SOUL.md'),
        os.path.join(WS, 'memory', 'lessons.json'),
        os.path.join(WS, 'memory', 'selflearn-state.json'),
        os.path.join(WS, 'aios', 'events', 'events.jsonl'),
    ]
    missing = [f for f in critical if not os.path.exists(f)]
    if missing:
        names = [os.path.basename(f) for f in missing]
        return "CRIT", f"å…³é”®æ–‡ä»¶ç¼ºå¤±: {', '.join(names)}"
    return "INFO", "å…³é”®æ–‡ä»¶å®Œæ•´"

def check_aios_score():
    """è§„åˆ™4: AIOS evolution score å¼‚å¸¸ï¼ˆå«APIè¶…æ—¶ç‡ï¼‰"""
    try:
        r = subprocess.run([PYTHON, '-m', 'aios', 'score'],
                          cwd=WS, capture_output=True, text=True, timeout=15)
        data = json.loads(r.stdout)
        grade = data.get('grade', 'unknown')
        score = data.get('score', 0)
        if grade == 'critical':
            return "CRIT", f"AIOS è¯„åˆ† critical ({score:.3f})"
        elif grade == 'degraded':
            return "WARN", f"AIOS è¯„åˆ† degraded ({score:.3f})"
        return "INFO", f"AIOS è¯„åˆ† {grade} ({score:.3f})"
    except:
        return "WARN", "AIOS score æ‰§è¡Œå¼‚å¸¸"

def check_backup():
    """è§„åˆ™5: å¤‡ä»½æ˜¯å¦æ­£å¸¸"""
    backup_dir = os.path.join(os.environ['USERPROFILE'], 'Desktop', 'autolearn_backups')
    if not os.path.isdir(backup_dir):
        return "WARN", "å¤‡ä»½ç›®å½•ä¸å­˜åœ¨"
    zips = sorted([f for f in os.listdir(backup_dir) if f.endswith('.zip')])
    if not zips:
        return "WARN", "æ— å¤‡ä»½æ–‡ä»¶"
    latest = zips[-1]
    latest_path = os.path.join(backup_dir, latest)
    age_hours = (time.time() - os.path.getmtime(latest_path)) / 3600
    size = os.path.getsize(latest_path)
    if age_hours > 48:
        return "WARN", f"æœ€è¿‘å¤‡ä»½å·²è¶…è¿‡ {int(age_hours)}h ({latest})"
    if size < 100:
        return "CRIT", f"æœ€è¿‘å¤‡ä»½æ–‡ä»¶å¼‚å¸¸å° ({size} bytes): {latest}"
    return "INFO", f"å¤‡ä»½æ­£å¸¸: {latest} ({round(size/1024/1024, 2)} MB, {int(age_hours)}h ago)"

def check_event_severity():
    """è§„åˆ™6: äº‹ä»¶ä¸¥é‡åº¦æ ‡å‡†åŒ– â€” fatal/æ­»å¾ªç¯æ£€æµ‹"""
    events_file = os.path.join(WS, 'aios', 'events', 'events.jsonl')
    if not os.path.exists(events_file):
        return "INFO", "æ— äº‹ä»¶æ–‡ä»¶"

    now = time.time()
    cutoff = now - 86400  # æœ€è¿‘24h
    fatal_count = 0
    loop_candidates = []  # (event_name, epoch) ç”¨äºæ£€æµ‹é‡å¤

    try:
        with open(events_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    ev = json.loads(line)
                except:
                    continue
                epoch = ev.get("epoch", 0)
                if epoch < cutoff:
                    continue

                status = ev.get("status", "ok")
                event_name = ev.get("event", "")
                layer = ev.get("layer", "")

                # fatal æ£€æµ‹ï¼šSECå±‚err + ç‰¹å®šå…³é”®è¯
                if status == "err" and (
                    "fatal" in event_name.lower() or
                    "circuit_breaker" in event_name.lower() or
                    (layer == "SEC" and "runtime_error" in event_name)
                ):
                    fatal_count += 1

                # æ­»å¾ªç¯æ£€æµ‹ï¼šåŒä¸€å‘½ä»¤çŸ­æ—¶é—´å†…é‡å¤æ‰§è¡Œ
                if status == "err" and layer == "TOOL":
                    loop_candidates.append((event_name, epoch))

        # æ­»å¾ªç¯åˆ¤å®šï¼šåŒä¸€ event_name åœ¨ DEDUP_WINDOW_SECONDS å†…å‡ºç° >= 3 æ¬¡
        loop_detected = []
        from collections import Counter
        if loop_candidates:
            # æŒ‰ event_name åˆ†ç»„ï¼Œæ£€æŸ¥æ—¶é—´çª—å£å†…çš„å¯†åº¦
            by_name = {}
            for name, ep in loop_candidates:
                by_name.setdefault(name, []).append(ep)
            for name, epochs in by_name.items():
                epochs.sort()
                for i in range(len(epochs) - 2):
                    if epochs[i+2] - epochs[i] <= DEDUP_WINDOW_SECONDS:
                        loop_detected.append(name)
                        break

        issues = []
        if fatal_count > 0:
            issues.append(f"fataläº‹ä»¶ {fatal_count} ä¸ª")
        if loop_detected:
            issues.append(f"ç–‘ä¼¼æ­»å¾ªç¯: {', '.join(loop_detected[:3])}")

        if fatal_count > 0 or loop_detected:
            return "CRIT", f"äº‹ä»¶å¼‚å¸¸: {'; '.join(issues)}"
        return "INFO", "äº‹ä»¶ä¸¥é‡åº¦æ­£å¸¸"

    except Exception as e:
        return "WARN", f"äº‹ä»¶æ£€æŸ¥å¼‚å¸¸: {e}"

def check_executor_bypass():
    """è§„åˆ™7: æ‰§è¡Œå™¨ç»•è¿‡æ£€æµ‹ â€” å‘½ä»¤æ‰§è¡Œäº‹ä»¶æœªèµ° execute() å…¥å£"""
    events_file = os.path.join(WS, 'aios', 'events', 'events.jsonl')
    exec_log_file = os.path.join(WS, 'aios', 'events', 'execution_log.jsonl')
    if not os.path.exists(events_file):
        return "INFO", "æ— äº‹ä»¶æ–‡ä»¶"

    now = time.time()
    cutoff = now - 86400  # æœ€è¿‘24h

    # æ”¶é›† events.jsonl ä¸­çš„ TOOL å±‚æ‰§è¡Œäº‹ä»¶ï¼ˆexec_ å¼€å¤´ = èµ°äº† executorï¼‰
    tool_exec_events = 0
    executor_events = 0

    try:
        with open(events_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    ev = json.loads(line)
                except:
                    continue
                epoch = ev.get("epoch", 0)
                if epoch < cutoff:
                    continue
                layer = ev.get("layer", "")
                event_name = ev.get("event", "")
                payload = ev.get("payload") or {}

                if layer == "TOOL":
                    # tool_exec / tool_* æ˜¯ç›´æ¥æ‰§è¡Œ
                    if event_name.startswith("tool_"):
                        tool_exec_events += 1
                    # exec_ å¼€å¤´æ˜¯èµ°äº† executor.execute()
                    if event_name.startswith("exec_"):
                        executor_events += 1
                    # payload é‡Œæœ‰ terminal_state ä¹Ÿç®—èµ°äº† executor
                    if "terminal_state" in payload:
                        executor_events += 1

        # å¦‚æœæœ‰ tool æ‰§è¡Œäº‹ä»¶ä½†æ²¡æœ‰ä»»ä½•èµ° executor çš„ï¼Œå‘Šè­¦
        total_exec = tool_exec_events + executor_events
        if total_exec == 0:
            return "INFO", "æ— æ‰§è¡Œäº‹ä»¶"

        bypass_count = tool_exec_events  # tool_ å¼€å¤´çš„æ²¡èµ° executor
        if bypass_count > 0 and executor_events == 0:
            return "WARN", f"å…¨éƒ¨ {bypass_count} ä¸ªæ‰§è¡Œäº‹ä»¶æœªèµ° executor å…¥å£ï¼Œå»ºè®®è¿ç§»åˆ° execute()"
        elif bypass_count > executor_events * 2:
            return "WARN", f"æ‰§è¡Œå™¨ç»•è¿‡ç‡åé«˜: {bypass_count} ç»•è¿‡ vs {executor_events} æ­£è§„ ({bypass_count/(bypass_count+executor_events)*100:.0f}%)"
        return "INFO", f"æ‰§è¡Œå™¨è¦†ç›–æ­£å¸¸: {executor_events} æ­£è§„ / {bypass_count} æ—§è·¯å¾„"

    except Exception as e:
        return "WARN", f"æ‰§è¡Œå™¨ç»•è¿‡æ£€æŸ¥å¼‚å¸¸: {e}"

# --- Main ---

RULES = [
    ("consecutive_failures", "è¿ç»­å¤±è´¥", check_consecutive_failures),
    ("data_drop", "æ•°æ®é‡éª¤é™", check_data_drop),
    ("critical_files", "å…³é”®æ–‡ä»¶ç¼ºå¤±", check_critical_files),
    ("aios_score", "APIè¶…æ—¶/è¯„åˆ†", check_aios_score),
    ("backup", "å¤‡ä»½çŠ¶æ€", check_backup),
    ("event_severity", "äº‹ä»¶ä¸¥é‡åº¦/æ­»å¾ªç¯", check_event_severity),
    ("executor_bypass", "æ‰§è¡Œå™¨ç»•è¿‡", check_executor_bypass),
]

def run_checks():
    state = load_state()
    results = {"INFO": [], "WARN": [], "CRIT": []}
    notifications = []

    for rule_id, rule_name, check_fn in RULES:
        # æœ‰äº› check éœ€è¦ state å‚æ•°
        try:
            if rule_id == "consecutive_failures":
                level, msg = check_fn(state)
            else:
                level, msg = check_fn()
        except Exception as e:
            level, msg = "WARN", f"{rule_name} æ£€æŸ¥å¼‚å¸¸: {e}"

        full_msg = f"[{rule_name}] {msg}"
        results[level].append(full_msg)
        log_event(level, rule_id, msg)

        # é—­ç¯çŠ¶æ€æœºé›†æˆ
        if level in ("CRIT", "WARN"):
            alert_fsm.open_alert(rule_id, level, msg)
        else:
            # INFO = æ­£å¸¸ï¼Œè®°å½•æ¢å¤
            alert_fsm.record_recovery(rule_id)

        # CRIT éœ€è¦å®æ—¶æ¨é€ï¼Œä½†è¦æ£€æŸ¥å†·å´
        if level == "CRIT":
            if is_cooled_down(state, rule_id):
                notifications.append(full_msg)
                mark_alerted(state, rule_id)

    # æ£€æŸ¥ SLA è¶…æ—¶
    overdue = alert_fsm.check_sla()
    for a in overdue:
        sla_msg = f"â° SLAè¶…æ—¶: [{a['id']}] {a['severity']} {a['message']}"
        if is_cooled_down(state, f"sla_{a['id']}"):
            notifications.append(sla_msg)
            mark_alerted(state, f"sla_{a['id']}")

    # æ„ŸçŸ¥æ‰«æï¼ˆdispatcherï¼‰
    if HAS_DISPATCHER:
        try:
            aios_dispatch(run_sensors=True)
            actions = get_pending_actions()
            for a in actions:
                pri = a.get("priority", "normal")
                summary = a.get("summary", "")
                if pri == "high":
                    results["WARN"].append(f"[æ„ŸçŸ¥] {summary}")
                    log_event("WARN", "sensor", summary)
            if actions:
                clear_actions()
        except Exception:
            pass

    save_state(state)
    return results, notifications

def format_summary(results):
    lines = [f"ğŸ” å¼‚å¸¸æ£€æŸ¥ {datetime.now().strftime('%Y-%m-%d %H:%M')}"]
    lines.append(f"CRIT: {len(results['CRIT'])} | WARN: {len(results['WARN'])} | INFO: {len(results['INFO'])}")

    if results['CRIT']:
        lines.append("\nğŸ”´ CRIT:")
        for m in results['CRIT']:
            lines.append(f"  {m}")
    if results['WARN']:
        lines.append("\nğŸŸ¡ WARN:")
        for m in results['WARN']:
            lines.append(f"  {m}")

    if not results['CRIT'] and not results['WARN']:
        lines.append("ğŸŸ¢ å…¨éƒ¨æ­£å¸¸")

    # çŠ¶æ€æœºæ‘˜è¦
    s = alert_fsm.stats()
    active_total = s['open'] + s['ack']
    if active_total > 0 or s['overdue'] > 0:
        lines.append(f"\nğŸ“‹ å‘Šè­¦çŠ¶æ€: OPEN={s['open']} ACK={s['ack']} è¶…SLA={s['overdue']}")

    return '\n'.join(lines)

def get_recent_warns(days=7):
    """è·å–æœ€è¿‘Nå¤©çš„ WARN äº‹ä»¶ï¼Œä¾›å‘¨æŠ¥ä½¿ç”¨"""
    if not os.path.exists(ALERTS_LOG):
        return []
    cutoff = (datetime.now() - timedelta(days=days)).isoformat()
    warns = []
    with open(ALERTS_LOG, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                entry = json.loads(line)
                if entry['level'] == 'WARN' and entry['ts'] >= cutoff:
                    warns.append(entry)
            except:
                continue
    # åŒç±»åˆå¹¶
    merged = {}
    for w in warns:
        key = w['rule']
        if key not in merged:
            merged[key] = {'rule': key, 'message': w['message'], 'count': 1, 'last': w['ts']}
        else:
            merged[key]['count'] += 1
            merged[key]['last'] = w['ts']
            merged[key]['message'] = w['message']
    return list(merged.values())

if __name__ == '__main__':
    # å°è¯•ä»ç¼“å­˜åŠ è½½
    cached = load_cache()
    if cached:
        print(cached['summary'])
        if cached['notifications']:
            print("\nğŸ“¢ éœ€è¦ç«‹å³æ¨é€:")
            for n in cached['notifications']:
                print(f"  {n}")
        else:
            print("\né™é»˜: æ— éœ€æ¨é€")
        print("\nğŸ’¾ [ç¼“å­˜å‘½ä¸­]")
    else:
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œæ£€æŸ¥
        results, notifications = run_checks()
        summary = format_summary(results)
        print(summary)

        if notifications:
            print("\nğŸ“¢ éœ€è¦ç«‹å³æ¨é€:")
            for n in notifications:
                print(f"  {n}")
        else:
            print("\né™é»˜: æ— éœ€æ¨é€")
        
        # ä¿å­˜åˆ°ç¼“å­˜
        save_cache({
            'summary': summary,
            'notifications': notifications,
            'results': results
        })
